{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e453b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import subprocess as sp\n",
    "from dataclasses import dataclass, field\n",
    "from enum import IntEnum\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "from ultralytics import YOLOv10\n",
    "from torchreid.utils import FeatureExtractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6861ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Конфигурация детектора / ROI / трекинга ====\n",
    "\n",
    "# Порог для \"достаточно уверенного бокса\", который мы используем для обновления Калмана\n",
    "TRACK_CONF_THR = 0.85\n",
    "\n",
    "# Минимальная высота бокса в пикселях (ниже — игнорируем как \"слишком маленький\")\n",
    "MIN_BOX_HEIGHT = 24\n",
    "\n",
    "# ROI в относительных координатах (0..1) кадра: только объекты полностью внутри ROI участвуют в трекинге\n",
    "ROI_X1_REL = 0.0\n",
    "ROI_X2_REL = 0.1\n",
    "ROI_Y1_REL = 0.5\n",
    "ROI_Y2_REL = 0.1\n",
    "\n",
    "# Максимальное число appearance-фич, используемых для усреднения в треке\n",
    "REID_MAX_FEATURES = 20\n",
    "\n",
    "# Для каких классов включаем ReID (пока только люди)\n",
    "# COCO: 0 = person\n",
    "REID_ENABLED_CLASSES = {0}\n",
    "\n",
    "# ==== Список классов COCO (80) для подписи на кадре ====\n",
    "COCO_CLASSES = [\n",
    "    \"person\",\"bicycle\",\"car\",\"motorcycle\",\"airplane\",\"bus\",\"train\",\"truck\",\"boat\",\n",
    "    \"traffic light\",\"fire hydrant\",\"stop sign\",\"parking meter\",\"bench\",\"bird\",\"cat\",\n",
    "    \"dog\",\"horse\",\"sheep\",\"cow\",\"elephant\",\"bear\",\"zebra\",\"giraffe\",\"backpack\",\n",
    "    \"umbrella\",\"handbag\",\"tie\",\"suitcase\",\"frisbee\",\"skis\",\"snowboard\",\"sports ball\",\n",
    "    \"kite\",\"baseball bat\",\"baseball glove\",\"skateboard\",\"surfboard\",\"tennis racket\",\n",
    "    \"bottle\",\"wine glass\",\"cup\",\"fork\",\"knife\",\"spoon\",\"bowl\",\"banana\",\"apple\",\n",
    "    \"sandwich\",\"orange\",\"broccoli\",\"carrot\",\"hot dog\",\"pizza\",\"donut\",\"cake\",\"chair\",\n",
    "    \"couch\",\"potted plant\",\"bed\",\"dining table\",\"toilet\",\"tv\",\"laptop\",\"mouse\",\n",
    "    \"remote\",\"keyboard\",\"cell phone\",\"microwave\",\"oven\",\"toaster\",\"sink\",\n",
    "    \"refrigerator\",\"book\",\"clock\",\"vase\",\"scissors\",\"teddy bear\",\"hair drier\",\n",
    "    \"toothbrush\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84691c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== Загрузка YOLOv10-M c HF (COCO) ====\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"YOLO device:\", device)\n",
    "\n",
    "yolo_model = YOLOv10.from_pretrained(\"jameslahm/yolov10m\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90d25027",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_video_info(path: str):\n",
    "    \"\"\"\n",
    "    Возвращает (width, height, fps) для видео файлa path (через ffprobe).\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\", \"error\",\n",
    "        \"-select_streams\", \"v:0\",\n",
    "        \"-show_entries\", \"stream=width,height,r_frame_rate\",\n",
    "        \"-of\", \"default=noprint_wrappers=1:nokey=1\",\n",
    "        path,\n",
    "    ]\n",
    "    out = sp.check_output(cmd).decode(\"utf-8\").strip().split(\"\\n\")\n",
    "    width = int(out[0])\n",
    "    height = int(out[1])\n",
    "    num, den = out[2].split(\"/\")\n",
    "    fps = float(num) / float(den)\n",
    "    return width, height, fps\n",
    "\n",
    "\n",
    "def ffmpeg_frame_generator(path: str, resize_to=None):\n",
    "    \"\"\"\n",
    "    Генератор кадров BGR np.ndarray из видео через ffmpeg.\n",
    "    resize_to: (w,h) или None (оставить оригинальный размер).\n",
    "    \"\"\"\n",
    "    orig_w, orig_h, _ = get_video_info(path)\n",
    "    if resize_to is None:\n",
    "        out_w, out_h = orig_w, orig_h\n",
    "        vf_args = []\n",
    "    else:\n",
    "        out_w, out_h = resize_to\n",
    "        vf_args = [\"-vf\", f\"scale={out_w}:{out_h}\"]\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-i\", path,\n",
    "        \"-loglevel\", \"error\",\n",
    "        *vf_args,\n",
    "        \"-f\", \"rawvideo\",\n",
    "        \"-pix_fmt\", \"bgr24\",\n",
    "        \"pipe:1\",\n",
    "    ]\n",
    "    proc = sp.Popen(cmd, stdout=sp.PIPE, bufsize=10**8)\n",
    "\n",
    "    frame_size = out_w * out_h * 3\n",
    "    try:\n",
    "        while True:\n",
    "            raw = proc.stdout.read(frame_size)\n",
    "            if len(raw) != frame_size:\n",
    "                break\n",
    "            frame = np.frombuffer(raw, np.uint8).reshape((out_h, out_w, 3))\n",
    "            yield frame\n",
    "    finally:\n",
    "        if proc.stdout is not None:\n",
    "            proc.stdout.close()\n",
    "        proc.wait()\n",
    "\n",
    "\n",
    "def create_ffmpeg_writer(output_path: str, width: int, height: int, fps: float):\n",
    "    \"\"\"\n",
    "    Возвращает subprocess.Popen с открытым stdin для записи сырых кадров BGR.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-f\", \"rawvideo\",\n",
    "        \"-vcodec\", \"rawvideo\",\n",
    "        \"-pix_fmt\", \"bgr24\",\n",
    "        \"-s\", f\"{width}x{height}\",\n",
    "        \"-r\", f\"{fps}\",\n",
    "        \"-i\", \"pipe:0\",\n",
    "        \"-an\",\n",
    "        \"-vcodec\", \"libx264\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        output_path,\n",
    "    ]\n",
    "    proc = sp.Popen(cmd, stdin=sp.PIPE, bufsize=10**8)\n",
    "    return proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f282c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xyxy_to_xyah(boxes_xyxy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Преобразование (x1,y1,x2,y2) -> (x_c, y_c, a=w/h, h), OC-SORT style.\n",
    "    boxes_xyxy: (N,4)\n",
    "    \"\"\"\n",
    "    if boxes_xyxy.size == 0:\n",
    "        return np.zeros((0, 4), dtype=np.float32)\n",
    "    x1, y1, x2, y2 = boxes_xyxy[:, 0], boxes_xyxy[:, 1], boxes_xyxy[:, 2], boxes_xyxy[:, 3]\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    x_c = x1 + 0.5 * w\n",
    "    y_c = y1 + 0.5 * h\n",
    "    a = w / (h + 1e-6)\n",
    "    return np.stack([x_c, y_c, a, h], axis=-1).astype(np.float32)\n",
    "\n",
    "\n",
    "def xyah_to_xyxy(boxes_xyah: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Обратное преобразование (x_c, y_c, a, h) -> (x1,y1,x2,y2).\n",
    "    \"\"\"\n",
    "    if boxes_xyah.size == 0:\n",
    "        return np.zeros((0, 4), dtype=np.float32)\n",
    "    x_c, y_c, a, h = boxes_xyah[:, 0], boxes_xyah[:, 1], boxes_xyah[:, 2], boxes_xyah[:, 3]\n",
    "    w = a * h\n",
    "    x1 = x_c - 0.5 * w\n",
    "    y1 = y_c - 0.5 * h\n",
    "    x2 = x_c + 0.5 * w\n",
    "    y2 = y_c + 0.5 * h\n",
    "    return np.stack([x1, y1, x2, y2], axis=-1).astype(np.float32)\n",
    "\n",
    "\n",
    "def iou_matrix(boxes1_xyxy: np.ndarray, boxes2_xyxy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    IoU матрица для двух наборов боксов (N1,4) и (N2,4).\n",
    "    \"\"\"\n",
    "    if boxes1_xyxy.size == 0 or boxes2_xyxy.size == 0:\n",
    "        return np.zeros((boxes1_xyxy.shape[0], boxes2_xyxy.shape[0]), dtype=np.float32)\n",
    "\n",
    "    b1 = boxes1_xyxy[:, None, :]  # (N1,1,4)\n",
    "    b2 = boxes2_xyxy[None, :, :]  # (1,N2,4)\n",
    "\n",
    "    x1 = np.maximum(b1[..., 0], b2[..., 0])\n",
    "    y1 = np.maximum(b1[..., 1], b2[..., 1])\n",
    "    x2 = np.minimum(b1[..., 2], b2[..., 2])\n",
    "    y2 = np.minimum(b1[..., 3], b2[..., 3])\n",
    "\n",
    "    inter_w = np.maximum(0.0, x2 - x1)\n",
    "    inter_h = np.maximum(0.0, y2 - y1)\n",
    "    inter = inter_w * inter_h\n",
    "\n",
    "    area1 = (b1[..., 2] - b1[..., 0]) * (b1[..., 3] - b1[..., 1])\n",
    "    area2 = (b2[..., 2] - b2[..., 0]) * (b2[..., 3] - b2[..., 1])\n",
    "\n",
    "    union = area1 + area2 - inter + 1e-6\n",
    "    iou = inter / union\n",
    "    return iou.astype(np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f2d4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterXYAH:\n",
    "    \"\"\"\n",
    "    Простая реализация Калмана для состояния:\n",
    "      x = [x, y, a, h, vx, vy, va]^T\n",
    "\n",
    "    Наблюдение:\n",
    "      z = [x, y, a, h]^T\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dt: float = 1.0 / 30.0):\n",
    "        self.dt = float(dt)\n",
    "\n",
    "        # Размерности\n",
    "        self.dim_x = 7\n",
    "        self.dim_z = 4\n",
    "\n",
    "        # Матрица перехода\n",
    "        self.F = np.eye(self.dim_x, dtype=np.float32)\n",
    "        self.F[0, 4] = self.dt\n",
    "        self.F[1, 5] = self.dt\n",
    "        self.F[2, 6] = self.dt\n",
    "\n",
    "        # Матрица наблюдения\n",
    "        self.H = np.zeros((self.dim_z, self.dim_x), dtype=np.float32)\n",
    "        self.H[0, 0] = 1.0  # x\n",
    "        self.H[1, 1] = 1.0  # y\n",
    "        self.H[2, 2] = 1.0  # a\n",
    "        self.H[3, 3] = 1.0  # h\n",
    "\n",
    "        # Начальные ковариации\n",
    "        self.P = np.eye(self.dim_x, dtype=np.float32) * 10.0\n",
    "\n",
    "        # Шум процесса\n",
    "        q_pos = 1.0\n",
    "        q_vel = 10.0\n",
    "        self.Q = np.diag([q_pos, q_pos, q_pos, q_pos, q_vel, q_vel, q_vel]).astype(np.float32)\n",
    "\n",
    "        # Шум наблюдения\n",
    "        self.R = np.diag([10.0, 10.0, 1.0, 10.0]).astype(np.float32)\n",
    "\n",
    "        self.x = np.zeros((self.dim_x,), dtype=np.float32)\n",
    "        self.initialized = False\n",
    "\n",
    "    def initiate(self, z: np.ndarray):\n",
    "        \"\"\"\n",
    "        Инициализация по одному наблюдению z=[x,y,a,h].\n",
    "        \"\"\"\n",
    "        z = np.asarray(z, dtype=np.float32).reshape(-1)\n",
    "        self.x[:] = 0.0\n",
    "        self.x[0:4] = z[0:4]\n",
    "        self.P = np.eye(self.dim_x, dtype=np.float32) * 10.0\n",
    "        self.initialized = True\n",
    "\n",
    "    def predict(self):\n",
    "        if not self.initialized:\n",
    "            return\n",
    "        self.x = self.F @ self.x\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "\n",
    "    def project(self):\n",
    "        \"\"\"\n",
    "        Проекция в пространство наблюдений:\n",
    "        возвращает (z_pred, S) — ожидаемое наблюдение и ковариацию.\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            z_pred = np.zeros((self.dim_z,), dtype=np.float32)\n",
    "            S = np.eye(self.dim_z, dtype=np.float32)\n",
    "            return z_pred, S\n",
    "        z_pred = self.H @ self.x\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        return z_pred.astype(np.float32), S.astype(np.float32)\n",
    "\n",
    "    def update(self, z: np.ndarray):\n",
    "        \"\"\"\n",
    "        Обновление по наблюдению z=[x,y,a,h].\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            self.initiate(z)\n",
    "            return\n",
    "\n",
    "        z = np.asarray(z, dtype=np.float32).reshape(-1)\n",
    "        z_pred, S = self.project()\n",
    "        y = z - z_pred  # innovation\n",
    "\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S + 1e-9 * np.eye(self.dim_z, dtype=np.float32))\n",
    "\n",
    "        self.x = self.x + K @ y\n",
    "        I = np.eye(self.dim_x, dtype=np.float32)\n",
    "        self.P = (I - K @ self.H) @ self.P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217ffe46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==== ReID: OSNet (MSMT17) для людей ====\n",
    "\n",
    "REID_PERSON_CLASS = 0  # COCO: 0 = person\n",
    "\n",
    "osnet_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"OSNet device:\", osnet_device)\n",
    "\n",
    "# !!! ВАЖНО: поменяй путь на фактический путь к весам osnet_x1_0_msmt17.pt !!!\n",
    "OSNET_WEIGHTS_PATH = r\"osnet_x1_0_msmt17.pth\"\n",
    "\n",
    "person_reid_extractor = FeatureExtractor(\n",
    "    model_name=\"osnet_x1_0\",\n",
    "    model_path=OSNET_WEIGHTS_PATH,\n",
    "    device=osnet_device,\n",
    ")\n",
    "print(\"[ReID] OSNet x1_0 MSMT17 загружен\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213c13be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def maha_distance_matrix(tracks_xyah: np.ndarray, tracks_S: np.ndarray, dets_xyah: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Махаланобисова дистанция d^2 между предсказанными треками (mean z_pred)\n",
    "    и наблюдениями dets_xyah.\n",
    "    tracks_xyah: (T,4) — z_pred\n",
    "    tracks_S:   (T,4,4) — ковариации в пространстве наблюдений\n",
    "    dets_xyah:  (N,4)\n",
    "    \"\"\"\n",
    "    T = tracks_xyah.shape[0]\n",
    "    N = dets_xyah.shape[0]\n",
    "    if T == 0 or N == 0:\n",
    "        return np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    d2 = np.zeros((T, N), dtype=np.float32)\n",
    "    for t in range(T):\n",
    "        S_inv = np.linalg.inv(tracks_S[t] + 1e-9 * np.eye(4, dtype=np.float32))\n",
    "        diff = dets_xyah - tracks_xyah[t]  # (N,4)\n",
    "        d2[t] = np.einsum(\"ni,ij,nj->n\", diff, S_inv, diff)\n",
    "    return d2\n",
    "\n",
    "\n",
    "def extract_person_reid_features(frame_bgr: np.ndarray, det: dict):\n",
    "    \"\"\"\n",
    "    frame_bgr : (H,W,3) BGR\n",
    "    det       : словарь результата run_yolo10_on_frame\n",
    "\n",
    "    Возвращает:\n",
    "      features   : (N, 512) float32, L2-нормированные\n",
    "      valid_mask : (N,) bool — True там, где фича реально посчитана (person)\n",
    "    \"\"\"\n",
    "    boxes = np.asarray(det[\"xyxy\"], dtype=np.float32)  # (N,4)\n",
    "    cls   = np.asarray(det[\"cls\"],   dtype=np.int32)\n",
    "    N = boxes.shape[0]\n",
    "\n",
    "    if N == 0:\n",
    "        return np.zeros((0, 512), dtype=np.float32), np.zeros((0,), dtype=bool)\n",
    "\n",
    "    H, W, _ = frame_bgr.shape\n",
    "\n",
    "    crops   = []\n",
    "    idx_map = []\n",
    "\n",
    "    for i in range(N):\n",
    "        if cls[i] != REID_PERSON_CLASS:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        x1 = max(0, min(W - 1, int(x1)))\n",
    "        y1 = max(0, min(H - 1, int(y1)))\n",
    "        x2 = max(0, min(W - 1, int(x2)))\n",
    "        y2 = max(0, min(H - 1, int(y2)))\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        crop_bgr = frame_bgr[y1:y2, x1:x2, :]\n",
    "        if crop_bgr.size == 0:\n",
    "            continue\n",
    "\n",
    "        crop_bgr = cv2.resize(crop_bgr, (128, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        crop_rgb = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        crops.append(crop_rgb)\n",
    "        idx_map.append(i)\n",
    "\n",
    "    features   = np.zeros((N, 512), dtype=np.float32)\n",
    "    valid_mask = np.zeros((N,),       dtype=bool)\n",
    "\n",
    "    if len(crops) == 0:\n",
    "        return features, valid_mask\n",
    "\n",
    "    with torch.no_grad():\n",
    "        feats = person_reid_extractor(crops)\n",
    "        if isinstance(feats, torch.Tensor):\n",
    "            feats = feats.cpu().numpy()\n",
    "\n",
    "    for j, det_idx in enumerate(idx_map):\n",
    "        v = feats[j].astype(np.float32)\n",
    "        n = np.linalg.norm(v) + 1e-12\n",
    "        v /= n\n",
    "        features[det_idx] = v\n",
    "        valid_mask[det_idx] = True\n",
    "\n",
    "    return features, valid_mask\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def byte_maha_associate(\n",
    "    tracks_xyah: np.ndarray,\n",
    "    tracks_S: np.ndarray,\n",
    "    dets_xyxy: np.ndarray,\n",
    "    dets_xyah: np.ndarray,\n",
    "    dets_scores: np.ndarray,\n",
    "    valid_size_mask: np.ndarray,\n",
    "    inside_roi_mask: np.ndarray,\n",
    "    thr_high: float,\n",
    "    thr_low: float,\n",
    "    iou_thresh_high: float,\n",
    "    iou_thresh_low: float,\n",
    "    gate_thresh: float,\n",
    "    alpha: float,\n",
    "    beta: float,\n",
    "    appearance_cost_high: np.ndarray | None,\n",
    "    track_classes: np.ndarray,\n",
    "    det_classes: np.ndarray,\n",
    "):\n",
    "    \"\"\"\n",
    "    Каскадная ассоциация ByteTrack + Махаланобис + Венгерский.\n",
    "\n",
    "    Вход:\n",
    "      tracks_xyah   : (T,4) — z_pred треков (x,y,a,h)\n",
    "      tracks_S      : (T,4,4) — ковариации в пространстве наблюдений\n",
    "      dets_xyxy     : (N,4) — детекции (x1,y1,x2,y2)\n",
    "      dets_xyah     : (N,4) — те же детекции в формате (x,y,a,h)\n",
    "      dets_scores   : (N,)  — score детекций\n",
    "      valid_size_mask : (N,) bool — достаточно крупные боксы\n",
    "      inside_roi_mask : (N,) bool — полностью внутри ROI\n",
    "      thr_high, thr_low: пороги ByteTrack\n",
    "      iou_thresh_high, iou_thresh_low: пороги по IoU\n",
    "      gate_thresh   : порог по Махаланобис-квадрату\n",
    "      alpha, beta   : веса для комбинированной стоимости α·(1−IoU)+β·d_app\n",
    "      appearance_cost_high : (T,N) или None — d_app для HIGH-детекций\n",
    "      track_classes : (T,) int\n",
    "      det_classes   : (N,) int\n",
    "\n",
    "    Выход:\n",
    "      словарь с полями:\n",
    "        \"matches_high\"       : (K1,2) int (t_idx, d_idx)\n",
    "        \"matches_low\"        : (K2,2) int (t_idx, d_idx)\n",
    "        \"unmatched_tracks\"   : (T_u,) int\n",
    "        \"unmatched_dets_high\": (D_h_u,) int\n",
    "        \"unmatched_dets_low\" : (D_l_u,) int\n",
    "    \"\"\"\n",
    "    T = tracks_xyah.shape[0]\n",
    "    N = dets_xyxy.shape[0]\n",
    "\n",
    "    dets_scores = np.asarray(dets_scores, dtype=np.float32)\n",
    "\n",
    "    # --- разбиение на high / low по ByteTrack ---\n",
    "    high_mask = (dets_scores >= thr_high) & valid_size_mask & inside_roi_mask\n",
    "    low_mask  = (dets_scores >= thr_low) & (dets_scores < thr_high) & valid_size_mask & inside_roi_mask\n",
    "\n",
    "    high_idxs = np.where(high_mask)[0]\n",
    "    low_idxs  = np.where(low_mask)[0]\n",
    "\n",
    "    matches_high = []\n",
    "    matches_low  = []\n",
    "\n",
    "    all_tracks_idx = np.arange(T, dtype=np.int32)\n",
    "    unmatched_tracks = all_tracks_idx.copy()\n",
    "    unmatched_dets_high = high_idxs.copy()\n",
    "    unmatched_dets_low  = low_idxs.copy()\n",
    "\n",
    "    LARGE = 1e6\n",
    "\n",
    "    # --- A) HIGH-конфиденс стадия ---\n",
    "    if T > 0 and high_idxs.size > 0:\n",
    "        dets_h_xyxy = dets_xyxy[high_idxs]\n",
    "        dets_h_xyah = dets_xyah[high_idxs]\n",
    "        dets_h_cls  = det_classes[high_idxs]\n",
    "\n",
    "        # IoU\n",
    "        tracks_xyxy = xyah_to_xyxy(tracks_xyah)\n",
    "        iou_h = iou_matrix(tracks_xyxy, dets_h_xyxy)          # (T,Nh)\n",
    "        iou_dist_h = 1.0 - iou_h\n",
    "\n",
    "        # Mahalanobis\n",
    "        maha_h = maha_distance_matrix(tracks_xyah, tracks_S, dets_h_xyah)\n",
    "        gate_mask = maha_h <= gate_thresh\n",
    "\n",
    "        # appearance (если есть)\n",
    "        if appearance_cost_high is not None and appearance_cost_high.shape == iou_h.shape:\n",
    "            d_app_h = appearance_cost_high[:, high_idxs]\n",
    "        else:\n",
    "            d_app_h = np.zeros_like(iou_h, dtype=np.float32)\n",
    "\n",
    "        cost_h = alpha * iou_dist_h + beta * d_app_h\n",
    "\n",
    "        # инвалидация по классу + гейтинг\n",
    "        for t in range(T):\n",
    "            for j, d_global in enumerate(high_idxs):\n",
    "                if track_classes[t] != det_classes[d_global]:\n",
    "                    cost_h[t, j] = LARGE\n",
    "                elif not gate_mask[t, j]:\n",
    "                    cost_h[t, j] = LARGE\n",
    "\n",
    "        row_ind, col_ind = linear_sum_assignment(cost_h)\n",
    "\n",
    "        matched_tracks_mask = np.zeros(T, dtype=bool)\n",
    "        matched_dets_mask_h = np.zeros(high_idxs.size, dtype=bool)\n",
    "\n",
    "        for r, c in zip(row_ind, col_ind):\n",
    "            if cost_h[r, c] >= LARGE:\n",
    "                continue\n",
    "            if iou_h[r, c] < iou_thresh_high:\n",
    "                continue\n",
    "\n",
    "            t_idx = r\n",
    "            d_idx = high_idxs[c]\n",
    "            matches_high.append((t_idx, d_idx))\n",
    "            matched_tracks_mask[t_idx] = True\n",
    "            matched_dets_mask_h[c] = True\n",
    "\n",
    "        unmatched_tracks    = all_tracks_idx[~matched_tracks_mask]\n",
    "        unmatched_dets_high = high_idxs[~matched_dets_mask_h]\n",
    "\n",
    "    # --- B) LOW-конфиденс стадия ByteTrack (только IoU+motion) ---\n",
    "    if unmatched_tracks.size > 0 and low_idxs.size > 0:\n",
    "        tracks_u_xyah = tracks_xyah[unmatched_tracks]\n",
    "        tracks_u_S    = tracks_S[unmatched_tracks]\n",
    "        tracks_u_cls  = track_classes[unmatched_tracks]\n",
    "\n",
    "        dets_l_xyxy = dets_xyxy[low_idxs]\n",
    "        dets_l_xyah = dets_xyah[low_idxs]\n",
    "        dets_l_cls  = det_classes[low_idxs]\n",
    "\n",
    "        tracks_u_xyxy = xyah_to_xyxy(tracks_u_xyah)\n",
    "        iou_l = iou_matrix(tracks_u_xyxy, dets_l_xyxy)\n",
    "        iou_dist_l = 1.0 - iou_l\n",
    "\n",
    "        maha_l = maha_distance_matrix(tracks_u_xyah, tracks_u_S, dets_l_xyah)\n",
    "        gate_mask_l = maha_l <= gate_thresh\n",
    "\n",
    "        cost_l = iou_dist_l.copy()\n",
    "\n",
    "        for ti, t_idx in enumerate(unmatched_tracks):\n",
    "            for j, d_global in enumerate(low_idxs):\n",
    "                if tracks_u_cls[ti] != dets_l_cls[j]:\n",
    "                    cost_l[ti, j] = LARGE\n",
    "                elif not gate_mask_l[ti, j]:\n",
    "                    cost_l[ti, j] = LARGE\n",
    "\n",
    "        row_ind_l, col_ind_l = linear_sum_assignment(cost_l)\n",
    "\n",
    "        matched_tracks_mask_u = np.zeros(unmatched_tracks.size, dtype=bool)\n",
    "        matched_dets_mask_l   = np.zeros(low_idxs.size, dtype=bool)\n",
    "\n",
    "        for r, c in zip(row_ind_l, col_ind_l):\n",
    "            if cost_l[r, c] >= LARGE:\n",
    "                continue\n",
    "            if iou_l[r, c] < iou_thresh_low:\n",
    "                continue\n",
    "\n",
    "            t_idx = unmatched_tracks[r]\n",
    "            d_idx = low_idxs[c]\n",
    "            matches_low.append((t_idx, d_idx))\n",
    "            matched_tracks_mask_u[r] = True\n",
    "            matched_dets_mask_l[c]   = True\n",
    "\n",
    "        unmatched_tracks   = unmatched_tracks[~matched_tracks_mask_u]\n",
    "        unmatched_dets_low = low_idxs[~matched_dets_mask_l]\n",
    "\n",
    "    return {\n",
    "        \"matches_high\": np.array(matches_high, dtype=np.int32).reshape(-1, 2),\n",
    "        \"matches_low\":  np.array(matches_low,  dtype=np.int32).reshape(-1, 2),\n",
    "        \"unmatched_tracks\":   unmatched_tracks,\n",
    "        \"unmatched_dets_high\": unmatched_dets_high,\n",
    "        \"unmatched_dets_low\":  unmatched_dets_low,\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d91eaeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrackState(IntEnum):\n",
    "    TENTATIVE = 0\n",
    "    CONFIRMED = 1\n",
    "    LOST = 2\n",
    "    REMOVED = 3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Track:\n",
    "    track_id: int\n",
    "    kf: \"KalmanFilterXYAH\"\n",
    "    class_id: int\n",
    "    n_init: int\n",
    "    max_time_lost: int\n",
    "\n",
    "    state: TrackState = TrackState.TENTATIVE\n",
    "    hits: int = 1\n",
    "    age: int = 1\n",
    "    time_since_update: int = 0\n",
    "    score: float = 0.0\n",
    "\n",
    "    last_xyah: np.ndarray = field(default_factory=lambda: np.zeros(4, dtype=np.float32))\n",
    "    last_S:   np.ndarray = field(default_factory=lambda: np.eye(4, dtype=np.float32))\n",
    "\n",
    "    trajectory_xyxy: list = field(default_factory=list)\n",
    "    features: list = field(default_factory=list)  # список np.ndarray (appearance-фичи)\n",
    "\n",
    "    # --- состояния ---\n",
    "\n",
    "    def is_tentative(self) -> bool:\n",
    "        return self.state == TrackState.TENTATIVE\n",
    "\n",
    "    def is_confirmed(self) -> bool:\n",
    "        return self.state == TrackState.CONFIRMED\n",
    "\n",
    "    def is_lost(self) -> bool:\n",
    "        return self.state == TrackState.LOST\n",
    "\n",
    "    def is_removed(self) -> bool:\n",
    "        return self.state == TrackState.REMOVED\n",
    "\n",
    "    # --- инициализация ---\n",
    "\n",
    "    def initiate_from_detection(self, meas_xyah: np.ndarray, score: float, feature: np.ndarray | None = None):\n",
    "        self.kf.initiate(meas_xyah)\n",
    "        z_pred, S = self.kf.project()\n",
    "        self.last_xyah = z_pred\n",
    "        self.last_S = S\n",
    "        self.score = float(score)\n",
    "        self.age = 1\n",
    "        self.hits = 1\n",
    "        self.time_since_update = 0\n",
    "\n",
    "        xyxy = xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "        self.trajectory_xyxy.append(xyxy)\n",
    "\n",
    "        if feature is not None:\n",
    "            self.features.append(feature)\n",
    "\n",
    "    # --- предсказание ---\n",
    "\n",
    "    def predict(self):\n",
    "        if not self.kf.initialized:\n",
    "            return\n",
    "\n",
    "        self.kf.predict()\n",
    "        z_pred, S = self.kf.project()\n",
    "        self.last_xyah = z_pred\n",
    "        self.last_S = S\n",
    "\n",
    "        self.age += 1\n",
    "        self.time_since_update += 1\n",
    "\n",
    "        xyxy = xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "        self.trajectory_xyxy.append(xyxy)\n",
    "\n",
    "    # --- обновление по детекции ---\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        meas_xyah: np.ndarray,\n",
    "        score: float,\n",
    "        feature: np.ndarray | None = None,\n",
    "        use_kalman: bool = True,\n",
    "    ):\n",
    "        self.time_since_update = 0\n",
    "        self.hits += 1\n",
    "        self.score = float(score)\n",
    "\n",
    "        if use_kalman:\n",
    "            self.kf.update(meas_xyah)\n",
    "\n",
    "        z_pred, S = self.kf.project()\n",
    "        self.last_xyah = z_pred\n",
    "        self.last_S = S\n",
    "\n",
    "        xyxy = xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "        if self.trajectory_xyxy:\n",
    "            self.trajectory_xyxy[-1] = xyxy\n",
    "        else:\n",
    "            self.trajectory_xyxy.append(xyxy)\n",
    "\n",
    "        if feature is not None:\n",
    "            self.features.append(feature)\n",
    "\n",
    "        if self.state == TrackState.TENTATIVE and self.hits >= self.n_init:\n",
    "            self.state = TrackState.CONFIRMED\n",
    "        elif self.state == TrackState.LOST:\n",
    "            self.state = TrackState.CONFIRMED\n",
    "\n",
    "    # --- \"пропуск\" кадра ---\n",
    "\n",
    "    def mark_missed(self):\n",
    "        if self.state == TrackState.TENTATIVE:\n",
    "            self.state = TrackState.REMOVED\n",
    "        elif self.state in (TrackState.CONFIRMED, TrackState.LOST):\n",
    "            if self.time_since_update > self.max_time_lost:\n",
    "                self.state = TrackState.REMOVED\n",
    "            else:\n",
    "                self.state = TrackState.LOST\n",
    "\n",
    "    # --- геттеры ---\n",
    "\n",
    "    def current_xyxy(self) -> np.ndarray:\n",
    "        return xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "\n",
    "    # --- ID-банк (усреднение последних K фич) ---\n",
    "\n",
    "    def get_feature_centroid(self, max_k: int = REID_MAX_FEATURES) -> np.ndarray | None:\n",
    "        \"\"\"\n",
    "        Возвращает L2-нормированный центроид последних max_k appearance-фич\n",
    "        или None, если фич ещё нет.\n",
    "        \"\"\"\n",
    "        if not self.features:\n",
    "            return None\n",
    "\n",
    "        feats = self.features[-int(max_k):]\n",
    "        arr = np.stack(feats, axis=0).astype(np.float32)\n",
    "\n",
    "        # ещё раз L2-нормируем\n",
    "        norms = np.linalg.norm(arr, axis=1, keepdims=True) + 1e-12\n",
    "        arr = arr / norms\n",
    "\n",
    "        centroid = arr.mean(axis=0)\n",
    "        c_norm = float(np.linalg.norm(centroid))\n",
    "        if c_norm > 0.0:\n",
    "            centroid /= c_norm\n",
    "        return centroid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61396c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_appearance_cost_matrix(\n",
    "    tracks: list[Track],\n",
    "    det_classes: np.ndarray,\n",
    "    det_features: np.ndarray,\n",
    "    enabled_classes: set[int] = REID_ENABLED_CLASSES,\n",
    "    max_features: int = REID_MAX_FEATURES,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    d_app(t,d) = 1 - cos_sim(track_centroid, det_feature)\n",
    "    Для неподдерживаемых классов или отсутствующих фич — 0.\n",
    "    \"\"\"\n",
    "    if not tracks:\n",
    "        return np.zeros((0, det_features.shape[0]), dtype=np.float32)\n",
    "\n",
    "    det_classes  = np.asarray(det_classes,  dtype=np.int32)\n",
    "    det_features = np.asarray(det_features, dtype=np.float32)\n",
    "\n",
    "    T = len(tracks)\n",
    "    N = det_features.shape[0]\n",
    "\n",
    "    if N == 0:\n",
    "        return np.zeros((T, 0), dtype=np.float32)\n",
    "\n",
    "    cost_app = np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    for ti, tr in enumerate(tracks):\n",
    "        if tr.class_id not in enabled_classes:\n",
    "            continue\n",
    "\n",
    "        centroid = tr.get_feature_centroid(max_k=max_features)\n",
    "        if centroid is None:\n",
    "            continue\n",
    "\n",
    "        centroid = centroid.astype(np.float32)\n",
    "        centroid /= (np.linalg.norm(centroid) + 1e-12)\n",
    "\n",
    "        mask = (det_classes == tr.class_id)\n",
    "        idxs = np.where(mask)[0]\n",
    "        if idxs.size == 0:\n",
    "            continue\n",
    "\n",
    "        feats = det_features[idxs]\n",
    "        feats /= (np.linalg.norm(feats, axis=1, keepdims=True) + 1e-12)\n",
    "\n",
    "        sims = feats @ centroid\n",
    "        sims = np.clip(sims, -1.0, 1.0)\n",
    "        d_app = 1.0 - sims\n",
    "\n",
    "        cost_app[ti, idxs] = d_app.astype(np.float32)\n",
    "\n",
    "    return cost_app\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7a539a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9923c9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    \"\"\"\n",
    "    Трекер OC-SORT/DeepSORT-стиля:\n",
    "\n",
    "      - Калман [x,y,a,h,vx,vy,va]\n",
    "      - ByteTrack + Махаланобис + Венгерский\n",
    "      - Жизненный цикл треков\n",
    "      - appearance (OSNet) через Track.features + get_feature_centroid\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fps: float,\n",
    "        n_init: int = 3,\n",
    "        max_time_lost: int = 30,\n",
    "        thr_high: float = 0.5,\n",
    "        thr_low: float = 0.1,\n",
    "        iou_thresh_high: float = 0.3,\n",
    "        iou_thresh_low: float = 0.1,\n",
    "        gate_thresh: float = 5.99,\n",
    "        alpha: float = 0.5,\n",
    "        beta: float = 0.5,\n",
    "        track_conf_thr: float = TRACK_CONF_THR,\n",
    "    ):\n",
    "        self.dt = 1.0 / float(fps)\n",
    "        self.n_init = int(n_init)\n",
    "        self.max_time_lost = int(max_time_lost)\n",
    "\n",
    "        self.thr_high = float(thr_high)\n",
    "        self.thr_low = float(thr_low)\n",
    "        self.iou_thresh_high = float(iou_thresh_high)\n",
    "        self.iou_thresh_low = float(iou_thresh_low)\n",
    "        self.gate_thresh = float(gate_thresh)\n",
    "        self.alpha = float(alpha)\n",
    "        self.beta = float(beta)\n",
    "        self.track_conf_thr = float(track_conf_thr)\n",
    "\n",
    "        self.tracks: list[Track] = []\n",
    "        self._next_id: int = 1\n",
    "\n",
    "    # --- внутренний помощник для создания трека ---\n",
    "\n",
    "    def _spawn_track(\n",
    "        self,\n",
    "        meas_xyah: np.ndarray,\n",
    "        score: float,\n",
    "        class_id: int,\n",
    "        feature: np.ndarray | None = None,\n",
    "    ):\n",
    "        kf = KalmanFilterXYAH(dt=self.dt)\n",
    "        tr = Track(\n",
    "            track_id=self._next_id,\n",
    "            kf=kf,\n",
    "            class_id=int(class_id),\n",
    "            n_init=self.n_init,\n",
    "            max_time_lost=self.max_time_lost,\n",
    "        )\n",
    "        tr.initiate_from_detection(meas_xyah, score, feature=feature)\n",
    "        self.tracks.append(tr)\n",
    "        self._next_id += 1\n",
    "\n",
    "    # --- основной шаг трекера ---\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        det: dict,\n",
    "        det_features: np.ndarray | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Обновление трекера по детекциям одного кадра.\n",
    "        det — словарь от run_yolo10_on_frame(...)\n",
    "        det_features — (N,512) appearance-фичи детекций (OSNet).\n",
    "        \"\"\"\n",
    "        # удалить REMOVED\n",
    "        self.tracks = [t for t in self.tracks if not t.is_removed()]\n",
    "\n",
    "        # предсказать все треки\n",
    "        for t in self.tracks:\n",
    "            t.predict()\n",
    "\n",
    "        T = len(self.tracks)\n",
    "        if T > 0:\n",
    "            tracks_xyah = np.stack([t.last_xyah for t in self.tracks], axis=0)\n",
    "            tracks_S    = np.stack([t.last_S   for t in self.tracks], axis=0)\n",
    "            track_classes = np.array([t.class_id for t in self.tracks], dtype=np.int32)\n",
    "        else:\n",
    "            tracks_xyah = np.zeros((0, 4), dtype=np.float32)\n",
    "            tracks_S    = np.zeros((0, 4, 4), dtype=np.float32)\n",
    "            track_classes = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "        dets_xyxy        = np.asarray(det[\"xyxy\"],            dtype=np.float32)\n",
    "        scores           = np.asarray(det[\"scores\"],          dtype=np.float32)\n",
    "        det_classes      = np.asarray(det[\"cls\"],             dtype=np.int32)\n",
    "        valid_size_mask  = np.asarray(det[\"valid_size_mask\"], dtype=bool)\n",
    "        inside_roi_mask  = np.asarray(det[\"inside_roi_mask\"], dtype=bool)\n",
    "\n",
    "        N = dets_xyxy.shape[0]\n",
    "        if N == 0:\n",
    "            for t in self.tracks:\n",
    "                t.mark_missed()\n",
    "            self.tracks = [t for t in self.tracks if not t.is_removed()]\n",
    "            return self.tracks\n",
    "\n",
    "        dets_xyah = xyxy_to_xyah(dets_xyxy)\n",
    "\n",
    "        # appearance-cost для HIGH-конфиденс стадии\n",
    "        appearance_cost_high = None\n",
    "        if det_features is not None and T > 0:\n",
    "            appearance_cost_high = compute_appearance_cost_matrix(\n",
    "                tracks=self.tracks,\n",
    "                det_classes=det_classes,\n",
    "                det_features=det_features,\n",
    "                enabled_classes=REID_ENABLED_CLASSES,\n",
    "                max_features=REID_MAX_FEATURES,\n",
    "            )\n",
    "\n",
    "        assoc = byte_maha_associate(\n",
    "            tracks_xyah=tracks_xyah,\n",
    "            tracks_S=tracks_S,\n",
    "            dets_xyxy=dets_xyxy,\n",
    "            dets_xyah=dets_xyah,\n",
    "            dets_scores=scores,\n",
    "            valid_size_mask=valid_size_mask,\n",
    "            inside_roi_mask=inside_roi_mask,\n",
    "            thr_high=self.thr_high,\n",
    "            thr_low=self.thr_low,\n",
    "            iou_thresh_high=self.iou_thresh_high,\n",
    "            iou_thresh_low=self.iou_thresh_low,\n",
    "            gate_thresh=self.gate_thresh,\n",
    "            alpha=self.alpha,\n",
    "            beta=self.beta,\n",
    "            appearance_cost_high=appearance_cost_high,\n",
    "            track_classes=track_classes,\n",
    "            det_classes=det_classes,\n",
    "        )\n",
    "\n",
    "        matches_high       = assoc[\"matches_high\"]\n",
    "        matches_low        = assoc[\"matches_low\"]\n",
    "        unmatched_tracks   = assoc[\"unmatched_tracks\"]\n",
    "        unmatched_dets_high = assoc[\"unmatched_dets_high\"]\n",
    "        unmatched_dets_low  = assoc[\"unmatched_dets_low\"]\n",
    "\n",
    "        matched_tracks_mask = np.zeros(T, dtype=bool)\n",
    "\n",
    "        # HIGH-конфиденс обновления\n",
    "        for t_idx, d_idx in matches_high:\n",
    "            matched_tracks_mask[t_idx] = True\n",
    "            meas_xyah = dets_xyah[d_idx]\n",
    "            sc        = scores[d_idx]\n",
    "            feat      = det_features[d_idx] if det_features is not None else None\n",
    "            use_kalman = (sc >= self.track_conf_thr)\n",
    "            self.tracks[t_idx].update(meas_xyah, sc, feature=feat, use_kalman=use_kalman)\n",
    "\n",
    "        # LOW-конфиденс ByteTrack\n",
    "        for t_idx, d_idx in matches_low:\n",
    "            matched_tracks_mask[t_idx] = True\n",
    "            meas_xyah = dets_xyah[d_idx]\n",
    "            sc        = scores[d_idx]\n",
    "            feat      = det_features[d_idx] if det_features is not None else None\n",
    "            use_kalman = (sc >= self.track_conf_thr)\n",
    "            self.tracks[t_idx].update(meas_xyah, sc, feature=feat, use_kalman=use_kalman)\n",
    "\n",
    "        # треки без матча\n",
    "        for t_idx, tr in enumerate(self.tracks):\n",
    "            if not matched_tracks_mask[t_idx]:\n",
    "                tr.mark_missed()\n",
    "\n",
    "        # новые треки из unmatched HIGH\n",
    "        for d_idx in unmatched_dets_high:\n",
    "            meas_xyah = dets_xyah[d_idx]\n",
    "            sc        = scores[d_idx]\n",
    "            class_id  = det_classes[d_idx]\n",
    "            feat      = det_features[d_idx] if det_features is not None else None\n",
    "            self._spawn_track(meas_xyah, sc, int(class_id), feature=feat)\n",
    "\n",
    "        # REMOVED — убрать\n",
    "        self.tracks = [t for t in self.tracks if not t.is_removed()]\n",
    "\n",
    "        return self.tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f249108",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_roi_rect(frame_shape):\n",
    "    h, w, _ = frame_shape\n",
    "    x1 = int(ROI_X1_REL * w)\n",
    "    x2 = int(ROI_X2_REL * w)\n",
    "    y1 = int(ROI_Y1_REL * h)\n",
    "    y2 = int(ROI_Y2_REL * h)\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def run_yolo10_on_frame(frame_bgr: np.ndarray, conf_thr: float = 0.85):\n",
    "    \"\"\"\n",
    "    Запускает YOLOv10 на кадре, возвращает словарь с детекциями и масками:\n",
    "      xyxy, scores, cls, valid_size_mask, inside_roi_mask\n",
    "    \"\"\"\n",
    "    H, W, _ = frame_bgr.shape\n",
    "    roi_x1, roi_y1, roi_x2, roi_y2 = compute_roi_rect(frame_bgr.shape)\n",
    "\n",
    "    # === YOLOv10 ===\n",
    "    with torch.no_grad():\n",
    "        results = yolo_model.predict(\n",
    "            frame_bgr,\n",
    "            conf=conf_thr,\n",
    "            iou=0.5,\n",
    "            device=device,\n",
    "            verbose=False,\n",
    "            imgsz=960,\n",
    "        )[0]\n",
    "\n",
    "    if results.boxes is None or len(results.boxes) == 0:\n",
    "        return {\n",
    "            \"xyxy\": np.zeros((0, 4), dtype=np.float32),\n",
    "            \"scores\": np.zeros((0,), dtype=np.float32),\n",
    "            \"cls\": np.zeros((0,), dtype=np.int32),\n",
    "            \"valid_size_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"inside_roi_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"roi_xyxy\": (roi_x1, roi_y1, roi_x2, roi_y2),\n",
    "        }\n",
    "\n",
    "    boxes_xyxy = results.boxes.xyxy.cpu().numpy().astype(np.float32)\n",
    "    scores = results.boxes.conf.cpu().numpy().astype(np.float32)\n",
    "    cls = results.boxes.cls.cpu().numpy().astype(np.int32)\n",
    "\n",
    "    # фильтрация по размеру и ROI\n",
    "    h = boxes_xyxy[:, 3] - boxes_xyxy[:, 1]\n",
    "    valid_size_mask = h >= MIN_BOX_HEIGHT\n",
    "\n",
    "    inside_roi_mask = (\n",
    "        (boxes_xyxy[:, 0] >= roi_x1) &\n",
    "        (boxes_xyxy[:, 1] >= roi_y1) &\n",
    "        (boxes_xyxy[:, 2] <= roi_x2) &\n",
    "        (boxes_xyxy[:, 3] <= roi_y2)\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"xyxy\": boxes_xyxy,\n",
    "        \"scores\": scores,\n",
    "        \"cls\": cls,\n",
    "        \"valid_size_mask\": valid_size_mask,\n",
    "        \"inside_roi_mask\": inside_roi_mask,\n",
    "        \"roi_xyxy\": (roi_x1, roi_y1, roi_x2, roi_y2),\n",
    "    }\n",
    "\n",
    "def draw_detections(frame_bgr: np.ndarray, det: dict) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Отрисовка ROI и детекций с цветовой схемой:\n",
    "      - красный   — слишком маленький бокс (valid_size=False)\n",
    "      - оранжевый — достаточный размер, но score < TRACK_CONF_THR (внутри ROI)\n",
    "      - зелёный   — внутри ROI, достаточный размер и score >= TRACK_CONF_THR\n",
    "      - синий     — валиден по размеру, но вне ROI\n",
    "    \"\"\"\n",
    "    img = frame_bgr.copy()\n",
    "    H, W, _ = img.shape\n",
    "\n",
    "    roi_x1, roi_y1, roi_x2, roi_y2 = det[\"roi_xyxy\"]\n",
    "\n",
    "    # полупрозрачный бирюзовый ROI\n",
    "    overlay = img.copy()\n",
    "    cv2.rectangle(\n",
    "        overlay,\n",
    "        (roi_x1, roi_y1),\n",
    "        (roi_x2, roi_y2),\n",
    "        (255, 255, 0),  # BGR (голубой/бирюзовый)\n",
    "        thickness=-1,\n",
    "    )\n",
    "    alpha = 0.15\n",
    "    img = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    boxes = det[\"xyxy\"]\n",
    "    scores = det[\"scores\"]\n",
    "    cls = det[\"cls\"]\n",
    "    valid_size_mask = det[\"valid_size_mask\"]\n",
    "    inside_roi_mask = det[\"inside_roi_mask\"]\n",
    "\n",
    "    for i in range(boxes.shape[0]):\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        p1 = (int(x1), int(y1))\n",
    "        p2 = (int(x2), int(y2))\n",
    "\n",
    "        if not valid_size_mask[i]:\n",
    "            color = (0, 0, 255)        # красный\n",
    "        else:\n",
    "            if inside_roi_mask[i]:\n",
    "                if scores[i] >= TRACK_CONF_THR:\n",
    "                    color = (0, 255, 0)  # зелёный\n",
    "                else:\n",
    "                    color = (0, 165, 255)  # оранжевый\n",
    "            else:\n",
    "                color = (255, 0, 0)    # синий\n",
    "\n",
    "        cv2.rectangle(img, p1, p2, color, 1)\n",
    "\n",
    "        class_id = int(cls[i])\n",
    "        name = COCO_CLASSES[class_id] if 0 <= class_id < len(COCO_CLASSES) else str(class_id)\n",
    "        label = f\"{name} {scores[i]:.2f}\"\n",
    "\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.42,\n",
    "            color,\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    return img\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c1c9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_tracks_on_frame(\n",
    "    frame_bgr: np.ndarray,\n",
    "    tracks: list[Track],\n",
    "    draw_tentative: bool = True,\n",
    "    draw_lost: bool = False,\n",
    "    traj_len: int = 30,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Отрисовка треков поверх кадра:\n",
    "      - CONFIRMED — зелёный\n",
    "      - TENTATIVE — жёлтый\n",
    "      - LOST      — фиолетовый (если draw_lost=True)\n",
    "    + короткая траектория (последние traj_len центров).\n",
    "    \"\"\"\n",
    "    img = frame_bgr.copy()\n",
    "\n",
    "    for tr in tracks:\n",
    "        if tr.is_removed():\n",
    "            continue\n",
    "\n",
    "        if tr.is_confirmed():\n",
    "            color = (0, 255, 0)\n",
    "        elif tr.is_tentative():\n",
    "            if not draw_tentative:\n",
    "                continue\n",
    "            color = (0, 255, 255)\n",
    "        elif tr.is_lost():\n",
    "            if not draw_lost:\n",
    "                continue\n",
    "            color = (255, 0, 255)\n",
    "        else:\n",
    "            color = (255, 255, 255)\n",
    "\n",
    "        box_xyxy = tr.current_xyxy()\n",
    "        x1, y1, x2, y2 = box_xyxy\n",
    "        p1 = (int(x1), int(y1))\n",
    "        p2 = (int(x2), int(y2))\n",
    "\n",
    "        cv2.rectangle(img, p1, p2, color, 1)\n",
    "\n",
    "        label = f\"ID {tr.track_id} | c{tr.class_id}\"\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (p1[0], p1[1] - 7),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.42,\n",
    "            color,\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # траектория\n",
    "        if tr.trajectory_xyxy:\n",
    "            traj = tr.trajectory_xyxy[-traj_len:]\n",
    "            pts = []\n",
    "            for bx in traj:\n",
    "                cx = 0.5 * (bx[0] + bx[2])\n",
    "                cy = 0.5 * (bx[1] + bx[3])\n",
    "                pts.append((int(cx), int(cy)))\n",
    "\n",
    "            if len(pts) >= 2:\n",
    "                pts_arr = np.array(pts, dtype=np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(img, [pts_arr], isClosed=False, color=color, thickness=1)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94171e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = r\"vid.mp4\"\n",
    "output_path = r\"output_with_tracks_osnet.mp4\"\n",
    "\n",
    "orig_w, orig_h, fps = get_video_info(video_path)\n",
    "print(f\"Видео: {orig_w}x{orig_h}, fps={fps:.3f}\")\n",
    "\n",
    "tracker = Tracker(\n",
    "    fps=fps,\n",
    "    n_init=3,\n",
    "    max_time_lost=30,\n",
    "    thr_high=0.5,\n",
    "    thr_low=0.1,\n",
    "    iou_thresh_high=0.3,\n",
    "    iou_thresh_low=0.1,\n",
    "    gate_thresh=5.99,      # можно ужать относительно 9.48\n",
    "    alpha=0.5,\n",
    "    beta=0.5,\n",
    "    track_conf_thr=TRACK_CONF_THR,\n",
    ")\n",
    "\n",
    "gen = ffmpeg_frame_generator(video_path, resize_to=None)\n",
    "writer_proc = create_ffmpeg_writer(output_path, orig_w, orig_h, fps)\n",
    "\n",
    "try:\n",
    "    for idx, frame in enumerate(gen):\n",
    "        # # 1) детекции YOLOv10\n",
    "        # det = run_yolo10_on_frame(frame, conf_thr=0.25)\n",
    "\n",
    "        # # 2) OSNet-фичи для людей\n",
    "        # det_features, det_valid_mask = extract_person_reid_features(frame, det)\n",
    "\n",
    "        # # 3) обновление трекера\n",
    "        # tracks = tracker.update(det, det_features=det_features)\n",
    "\n",
    "        det = run_yolo10_on_frame(frame, conf_thr=0.25)\n",
    "        det_features, _ = extract_person_reid_features(frame, det)\n",
    "        tracks = tracker.update(det, det_features=det_features)\n",
    "\n",
    "        # 4) визуализация\n",
    "        frame_det = draw_detections(frame, det)\n",
    "        frame_out = draw_tracks_on_frame(frame_det, tracks)\n",
    "\n",
    "        writer_proc.stdin.write(frame_out.tobytes())\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Обработан кадр {idx}\")\n",
    "finally:\n",
    "    if writer_proc.stdin is not None:\n",
    "        writer_proc.stdin.close()\n",
    "    ret = writer_proc.wait()\n",
    "    print(\"ffmpeg завершился с кодом\", ret)\n",
    "    print(\"Готово, результат в:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f5a425a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef451557",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
