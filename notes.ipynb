{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e459f658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLOv10\n",
    "import torch\n",
    "\n",
    "# 1) Загружаем предобученный COCO-чекпоинт с HF\n",
    "model = YOLOv10.from_pretrained(\"jameslahm/yolov10m\")\n",
    "\n",
    "device = 0 if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from torchreid.utils import FeatureExtractor\n",
    "\n",
    "# ===== ReID: OSNet для людей =====\n",
    "\n",
    "REID_PERSON_CLASS = 0  # COCO: 0 = person\n",
    "\n",
    "osnet_device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(osnet_device)\n",
    "\n",
    "person_reid_extractor = FeatureExtractor(\n",
    "    model_name=\"osnet_x1_0\",\n",
    "    # путь к скачанному .pt с ReID-весами (MSMT17 / Market1501 и т.д.)\n",
    "    model_path=r\"osnet_x1_0_msmt17.pt\",\n",
    "    device=osnet_device,\n",
    ")\n",
    "print(f\"[ReID] OSNet инициализирован на {osnet_device}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc49fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_person_reid_features(frame_bgr: np.ndarray, det: dict):\n",
    "    \"\"\"\n",
    "    frame_bgr : np.ndarray (H, W, 3), BGR\n",
    "    det       : результат run_yolo10_on_frame\n",
    "\n",
    "    Возвращает:\n",
    "      - features: (N, 512) float32, L2-нормированные\n",
    "      - valid_mask: (N,) bool — True только для людей с успешно посчитанным признаком\n",
    "    \"\"\"\n",
    "    boxes = det[\"xyxy\"]      # (N,4)\n",
    "    cls   = det[\"cls\"]       # (N,)\n",
    "    N = boxes.shape[0]\n",
    "\n",
    "    if N == 0:\n",
    "        return np.zeros((0, 512), dtype=np.float32), np.zeros((0,), dtype=bool)\n",
    "\n",
    "    H, W, _ = frame_bgr.shape\n",
    "\n",
    "    crops = []\n",
    "    idx_map = []   # индексы детекций, для которых реально считаем ReID\n",
    "\n",
    "    # --- готовим кропы только для людей ---\n",
    "    for i in range(N):\n",
    "        if cls[i] != REID_PERSON_CLASS:\n",
    "            continue\n",
    "\n",
    "        x1, y1, x2, y2 = boxes[i]\n",
    "        x1 = max(0, min(W - 1, int(x1)))\n",
    "        y1 = max(0, min(H - 1, int(y1)))\n",
    "        x2 = max(0, min(W - 1, int(x2)))\n",
    "        y2 = max(0, min(H - 1, int(y2)))\n",
    "\n",
    "        if x2 <= x1 or y2 <= y1:\n",
    "            continue\n",
    "\n",
    "        crop_bgr = frame_bgr[y1:y2, x1:x2, :]\n",
    "        if crop_bgr.size == 0:\n",
    "            continue\n",
    "\n",
    "        # OSNet стандартно обучен на 256x128 (H,W)\n",
    "        crop_bgr = cv2.resize(crop_bgr, (128, 256), interpolation=cv2.INTER_LINEAR)\n",
    "        crop_rgb = cv2.cvtColor(crop_bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        crops.append(crop_rgb)\n",
    "        idx_map.append(i)\n",
    "\n",
    "    features = np.zeros((N, 512), dtype=np.float32)\n",
    "    valid_mask = np.zeros((N,), dtype=bool)\n",
    "\n",
    "    if len(crops) == 0:\n",
    "        return features, valid_mask\n",
    "\n",
    "    # torchreid FeatureExtractor умеет принимать список np.ndarray\n",
    "    with torch.no_grad():\n",
    "        feats = person_reid_extractor(crops)  # torch.Tensor или np.ndarray, (M,512)\n",
    "        if isinstance(feats, torch.Tensor):\n",
    "            feats = feats.cpu().numpy()\n",
    "\n",
    "    # L2-нормировка и расклад по исходным индексам\n",
    "    for j, det_idx in enumerate(idx_map):\n",
    "        v = feats[j].astype(np.float32)\n",
    "        norm = np.linalg.norm(v) + 1e-12\n",
    "        v /= norm\n",
    "        features[det_idx] = v\n",
    "        valid_mask[det_idx] = True\n",
    "\n",
    "    return features, valid_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b9cfc079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess as sp\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "def get_video_info(video_path: str):\n",
    "    \"\"\"\n",
    "    Возвращает (width, height, fps) для первого видеопотока.\n",
    "    Требует установленного ffprobe.\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffprobe\",\n",
    "        \"-v\", \"error\",\n",
    "        \"-select_streams\", \"v:0\",\n",
    "        \"-show_entries\", \"stream=width,height,avg_frame_rate\",\n",
    "        \"-of\", \"json\",\n",
    "        video_path,\n",
    "    ]\n",
    "\n",
    "    result = sp.run(cmd, stdout=sp.PIPE, stderr=sp.PIPE, text=True, check=True)\n",
    "    info = json.loads(result.stdout)\n",
    "    stream = info[\"streams\"][0]\n",
    "\n",
    "    width = int(stream[\"width\"])\n",
    "    height = int(stream[\"height\"])\n",
    "\n",
    "    fps_str = stream.get(\"avg_frame_rate\", \"0/1\")\n",
    "    num, den = map(int, fps_str.split(\"/\"))\n",
    "    fps = num / den if den != 0 else 0.0\n",
    "\n",
    "    return width, height, fps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f172050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ffmpeg_frame_generator(video_path: str, resize_to: tuple[int, int] | None = None):\n",
    "    \"\"\"\n",
    "    Читает видео через ffmpeg и выдаёт кадры как np.ndarray (H, W, 3) в BGR.\n",
    "\n",
    "    :param video_path: путь к .mp4\n",
    "    :param resize_to: (W, H) целевого кадра или None, чтобы оставить оригинал\n",
    "    \"\"\"\n",
    "    orig_w, orig_h, fps = get_video_info(video_path)\n",
    "    print(f\"Видео: {orig_w}x{orig_h}, fps={fps:.3f}\")\n",
    "\n",
    "    if resize_to is None:\n",
    "        out_w, out_h = orig_w, orig_h\n",
    "        scale_filter = \"scale=iw:ih\"   # без изменения размера\n",
    "    else:\n",
    "        out_w, out_h = resize_to\n",
    "        scale_filter = f\"scale={out_w}:{out_h}\"\n",
    "\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-hide_banner\",\n",
    "        \"-loglevel\", \"error\",\n",
    "        \"-nostdin\",\n",
    "        \"-i\", video_path,\n",
    "        \"-vf\", scale_filter,\n",
    "        \"-f\", \"rawvideo\",\n",
    "        \"-pix_fmt\", \"bgr24\",\n",
    "        \"-\"\n",
    "    ]\n",
    "\n",
    "    # Открываем ffmpeg-процесс\n",
    "    proc = sp.Popen(\n",
    "        cmd,\n",
    "        stdout=sp.PIPE,\n",
    "        stderr=sp.DEVNULL   # чтобы не забивался буфер stderr\n",
    "    )\n",
    "\n",
    "    frame_size = out_w * out_h * 3  # 3 канала BGR по 1 байту\n",
    "\n",
    "    try:\n",
    "        while True:\n",
    "            # читаем ровно один кадр\n",
    "            raw = proc.stdout.read(frame_size)\n",
    "            if not raw or len(raw) < frame_size:\n",
    "                break\n",
    "\n",
    "            frame = np.frombuffer(raw, np.uint8).reshape((out_h, out_w, 3))\n",
    "            yield frame\n",
    "\n",
    "    finally:\n",
    "        if proc.stdout is not None:\n",
    "            proc.stdout.close()\n",
    "        proc.wait()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "46bedb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "# Статический ROI в координатах кадра (x1, y1, x2, y2) или None для всего кадра\n",
    "# Пример: вырезать центральную полосу по высоте\n",
    "ROI = None\n",
    "ROI = (0, 360, 1280, 720)\n",
    "\n",
    "# Минимальная высота бокса в пикселях, чтобы бокс считался «валидным» для трекинга\n",
    "MIN_BOX_HEIGHT = 24.0\n",
    "\n",
    "# Порог уверенности для трекинга (Калман и т.д.)\n",
    "TRACK_CONF_THR = 0.85\n",
    "\n",
    "\n",
    "def run_yolo10_on_frame(\n",
    "    frame_bgr,\n",
    "    conf_thr: float = 0.25,           # порог для самой YOLO\n",
    "    roi=ROI,\n",
    "    min_box_height: float = MIN_BOX_HEIGHT,\n",
    "    track_conf_thr: float = TRACK_CONF_THR,  # порог для трекинга\n",
    "):\n",
    "    \"\"\"\n",
    "    Запускает YOLOv10 на полном кадре и возвращает детекции.\n",
    "\n",
    "    Возвращаемый словарь:\n",
    "      - xyxy: (N, 4) — все боксы после порога по conf_thr;\n",
    "      - scores: (N,) — вероятности;\n",
    "      - cls: (N,) — индексы классов;\n",
    "      - valid_size_mask: (N,) bool — True, если бокс достаточно высокий;\n",
    "      - inside_roi_mask: (N,) bool — True, если бокс целиком внутри ROI\n",
    "                                  (или все True, если ROI=None);\n",
    "      - conf_track_mask: (N,) bool — True, если score >= track_conf_thr;\n",
    "      - track_mask: (N,) bool — True, если бокс годен для трекинга\n",
    "                                (размер + ROI + уверенность);\n",
    "      - xyah: (M, 4) — (x, y, a, h) только для боксов с track_mask=True.\n",
    "    \"\"\"\n",
    "    H, W, _ = frame_bgr.shape\n",
    "\n",
    "    # --- 1. YOLO по всему кадру ---\n",
    "    results = model.predict(\n",
    "        source=frame_bgr,\n",
    "        imgsz=960,\n",
    "        device=device,\n",
    "        half=(device != \"cpu\"),\n",
    "        conf=conf_thr,\n",
    "        verbose=False,\n",
    "    )\n",
    "    res = results[0]\n",
    "\n",
    "    if res.boxes is None or len(res.boxes) == 0:\n",
    "        return {\n",
    "            \"xyxy\": np.zeros((0, 4), dtype=np.float32),\n",
    "            \"scores\": np.zeros((0,), dtype=np.float32),\n",
    "            \"cls\": np.zeros((0,), dtype=np.int32),\n",
    "            \"valid_size_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"inside_roi_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"conf_track_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"track_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"xyah\": np.zeros((0, 4), dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    boxes = res.boxes.xyxy.cpu().numpy().astype(np.float32)   # (N, 4)\n",
    "    scores = res.boxes.conf.cpu().numpy().astype(np.float32)  # (N,)\n",
    "    cls = res.boxes.cls.cpu().numpy().astype(np.int32)        # (N,)\n",
    "\n",
    "    # Дополнительная фильтрация по conf_thr (на всякий случай)\n",
    "    mask_conf = scores >= conf_thr\n",
    "    boxes = boxes[mask_conf]\n",
    "    scores = scores[mask_conf]\n",
    "    cls = cls[mask_conf]\n",
    "\n",
    "    if boxes.shape[0] == 0:\n",
    "        return {\n",
    "            \"xyxy\": boxes,\n",
    "            \"scores\": scores,\n",
    "            \"cls\": cls,\n",
    "            \"valid_size_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"inside_roi_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"conf_track_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"track_mask\": np.zeros((0,), dtype=bool),\n",
    "            \"xyah\": np.zeros((0, 4), dtype=np.float32),\n",
    "        }\n",
    "\n",
    "    # --- 2. Геометрия ---\n",
    "    w = boxes[:, 2] - boxes[:, 0]\n",
    "    h = boxes[:, 3] - boxes[:, 1]\n",
    "    x = boxes[:, 0] + w / 2.0\n",
    "    y = boxes[:, 1] + h / 2.0\n",
    "    a = w / np.maximum(h, 1e-6)\n",
    "\n",
    "    # --- 3. Маска по размеру ---\n",
    "    valid_size_mask = h >= float(min_box_height)\n",
    "\n",
    "    # --- 4. Маска по ROI (полностью внутри) ---\n",
    "    if roi is not None:\n",
    "        x1_roi, y1_roi, x2_roi, y2_roi = roi\n",
    "\n",
    "        # ограничиваем ROI границами кадра\n",
    "        x1_roi = max(0, min(W, x1_roi))\n",
    "        x2_roi = max(0, min(W, x2_roi))\n",
    "        y1_roi = max(0, min(H, y1_roi))\n",
    "        y2_roi = max(0, min(H, y2_roi))\n",
    "\n",
    "        if x2_roi <= x1_roi or y2_roi <= y1_roi:\n",
    "            raise ValueError(\"ROI имеет неположительный размер после обрезки по кадру\")\n",
    "\n",
    "        inside_roi_mask = (\n",
    "            (boxes[:, 0] >= x1_roi) &\n",
    "            (boxes[:, 1] >= y1_roi) &\n",
    "            (boxes[:, 2] <= x2_roi) &\n",
    "            (boxes[:, 3] <= y2_roi)\n",
    "        )\n",
    "    else:\n",
    "        inside_roi_mask = np.ones_like(valid_size_mask, dtype=bool)\n",
    "\n",
    "    # --- 5. Маска по уверенности для трекинга ---\n",
    "    conf_track_mask = scores >= float(track_conf_thr)\n",
    "\n",
    "    # --- 6. Итоговая маска для трекинга ---\n",
    "    track_mask = valid_size_mask & inside_roi_mask & conf_track_mask\n",
    "\n",
    "    # xyah только для тех, кто пойдёт в трекер\n",
    "    if np.any(track_mask):\n",
    "        xyah = np.stack(\n",
    "            [x[track_mask], y[track_mask], a[track_mask], h[track_mask]],\n",
    "            axis=1,\n",
    "        ).astype(np.float32)\n",
    "    else:\n",
    "        xyah = np.zeros((0, 4), dtype=np.float32)\n",
    "\n",
    "    return {\n",
    "        \"xyxy\": boxes,\n",
    "        \"scores\": scores,\n",
    "        \"cls\": cls,\n",
    "        \"valid_size_mask\": valid_size_mask,\n",
    "        \"inside_roi_mask\": inside_roi_mask,\n",
    "        \"conf_track_mask\": conf_track_mask,\n",
    "        \"track_mask\": track_mask,\n",
    "        \"xyah\": xyah,\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "# ---------- Отрисовка детекций на кадре ----------\n",
    "\n",
    "def draw_detections(frame_bgr: np.ndarray, det, roi=ROI):\n",
    "    \"\"\"\n",
    "    Рисует:\n",
    "      - полупрозрачный бирюзовый ROI (если задан),\n",
    "      - все детекции:\n",
    "          * красный  — слишком маленький по размеру (valid_size_mask=False);\n",
    "          * оранжевый — размер норм, но conf < TRACK_CONF_THR (conf_track_mask=False);\n",
    "          * зелёный — годный для трекинга (track_mask=True);\n",
    "          * синий — размер норм, conf >= TRACK_CONF_THR, но вне ROI.\n",
    "\n",
    "    Толщина линий = 1, fontScale = 0.42.\n",
    "    \"\"\"\n",
    "    img = frame_bgr.copy()\n",
    "\n",
    "    # --- 1. Полупрозрачный ROI ---\n",
    "    if roi is not None:\n",
    "        x1_roi, y1_roi, x2_roi, y2_roi = roi\n",
    "        H, W, _ = img.shape\n",
    "\n",
    "        x1_roi = max(0, min(W, x1_roi))\n",
    "        x2_roi = max(0, min(W, x2_roi))\n",
    "        y1_roi = max(0, min(H, y1_roi))\n",
    "        y2_roi = max(0, min(H, y2_roi))\n",
    "\n",
    "        if x2_roi > x1_roi and y2_roi > y1_roi:\n",
    "            overlay = img.copy()\n",
    "            roi_color = (255, 255, 0)  # бирюзовый-ish в BGR\n",
    "            cv2.rectangle(\n",
    "                overlay,\n",
    "                (x1_roi, y1_roi),\n",
    "                (x2_roi, y2_roi),\n",
    "                roi_color,\n",
    "                thickness=-1,\n",
    "            )\n",
    "            alpha = 0.2\n",
    "            img = cv2.addWeighted(overlay, alpha, img, 1 - alpha, 0)\n",
    "\n",
    "    # --- 2. Отрисовка боксов ---\n",
    "    boxes = det[\"xyxy\"]\n",
    "    scores = det[\"scores\"]\n",
    "    cls = det[\"cls\"]\n",
    "    valid_size_mask = det.get(\"valid_size_mask\", np.ones_like(scores, dtype=bool))\n",
    "    inside_roi_mask = det.get(\"inside_roi_mask\", np.ones_like(scores, dtype=bool))\n",
    "    conf_track_mask = det.get(\"conf_track_mask\", np.ones_like(scores, dtype=bool))\n",
    "    track_mask = det.get(\"track_mask\", valid_size_mask & inside_roi_mask & conf_track_mask)\n",
    "\n",
    "    names = getattr(model, \"names\", None)\n",
    "\n",
    "    for i, ((x1, y1, x2, y2), sc, cl) in enumerate(zip(boxes, scores, cls)):\n",
    "        is_valid_size = bool(valid_size_mask[i])\n",
    "        is_inside_roi = bool(inside_roi_mask[i])\n",
    "        is_conf_ok = bool(conf_track_mask[i])\n",
    "        is_track = bool(track_mask[i])\n",
    "\n",
    "        # Цвета в BGR\n",
    "        red = (0, 0, 255)\n",
    "        green = (0, 160, 0)\n",
    "        blue = (255, 0, 0)\n",
    "        orange = (0, 165, 255)\n",
    "\n",
    "        if not is_valid_size:\n",
    "            color = red               # маленький\n",
    "        elif not is_conf_ok:\n",
    "            color = orange            # размер норм, но уверенность < TRACK_CONF_THR\n",
    "        elif is_track:\n",
    "            color = green             # годен для трекинга (в ROI + conf + размер)\n",
    "        else:\n",
    "            color = blue              # размер и conf ок, но вне ROI\n",
    "\n",
    "        p1 = (int(x1), int(y1))\n",
    "        p2 = (int(x2), int(y2))\n",
    "        cv2.rectangle(img, p1, p2, color, 1)  # толщина 1\n",
    "\n",
    "        # Подпись: имя класса + score\n",
    "        if names is not None and int(cl) in names:\n",
    "            cls_name = names[int(cl)]\n",
    "        else:\n",
    "            cls_name = str(int(cl))\n",
    "\n",
    "        label = f\"{cls_name} {sc:.2f}\"\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (int(x1), int(y1) - 5),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.42,     # fontScale\n",
    "            color,\n",
    "            1,        # толщина шрифта\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "    return img\n",
    "\n",
    "\n",
    "# ---------- ffmpeg writer для выхода ----------\n",
    "\n",
    "def create_ffmpeg_writer(output_path: str, width: int, height: int, fps: float):\n",
    "    \"\"\"\n",
    "    Создаёт ffmpeg-процесс, принимающий сырые BGR кадры (rawvideo) на stdin\n",
    "    и записывающий mp4 (H.264).\n",
    "    \"\"\"\n",
    "    cmd = [\n",
    "        \"ffmpeg\",\n",
    "        \"-y\",\n",
    "        \"-loglevel\", \"error\",          # <− чтобы ffmpeg почти ничего не писал\n",
    "        \"-f\", \"rawvideo\",\n",
    "        \"-pix_fmt\", \"bgr24\",\n",
    "        \"-s\", f\"{width}x{height}\",\n",
    "        \"-r\", f\"{fps}\",\n",
    "        \"-i\", \"-\",\n",
    "        \"-an\",\n",
    "        \"-c:v\", \"libx264\",\n",
    "        \"-pix_fmt\", \"yuv420p\",\n",
    "        output_path,\n",
    "    ]\n",
    "\n",
    "    # Критично: не PIPE, а DEVNULL (или вообще не перенаправлять stderr)\n",
    "    proc = sp.Popen(cmd, stdin=sp.PIPE, stderr=sp.DEVNULL)\n",
    "    return proc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1f343c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное видео: 1280x720, fps=25.000\n",
      "Видео: 1280x720, fps=25.000\n",
      "Обработан кадр 0\n",
      "Обработан кадр 50\n",
      "Обработан кадр 100\n",
      "Обработан кадр 150\n",
      "Обработан кадр 200\n",
      "Обработан кадр 250\n",
      "Обработан кадр 300\n",
      "Обработан кадр 350\n",
      "Обработан кадр 400\n",
      "Обработан кадр 450\n",
      "Обработан кадр 500\n",
      "Обработан кадр 550\n",
      "Обработан кадр 600\n",
      "Обработан кадр 650\n",
      "Обработан кадр 700\n",
      "Обработан кадр 750\n",
      "Обработан кадр 800\n",
      "Обработан кадр 850\n",
      "Обработан кадр 900\n",
      "Обработан кадр 950\n",
      "Обработан кадр 1000\n",
      "Обработан кадр 1050\n",
      "Обработан кадр 1100\n",
      "Обработан кадр 1150\n",
      "Готово, выходное видео: vid_with_boxes.mp4\n"
     ]
    }
   ],
   "source": [
    "# ---------- Основной цикл: читаем → детектим → рисуем → пишем ----------\n",
    "\n",
    "video_path = r\"vid.mp4\"\n",
    "output_path_boxes = r\"vid_with_boxes.mp4\"\n",
    "\n",
    "orig_w, orig_h, fps = get_video_info(video_path)\n",
    "print(f\"Исходное видео: {orig_w}x{orig_h}, fps={fps:.3f}\")\n",
    "\n",
    "# Для корректного letterbox лучше оставить оригинальное разрешение,\n",
    "# YOLO сам приведёт к imgsz=960 внутри. Поэтому resize_to=None.\n",
    "gen = ffmpeg_frame_generator(video_path, resize_to=None)\n",
    "\n",
    "writer_proc = create_ffmpeg_writer(output_path_boxes, orig_w, orig_h, fps)\n",
    "\n",
    "try:\n",
    "    for idx, frame in enumerate(gen):\n",
    "        det = run_yolo10_on_frame(frame, conf_thr=0.25)  # порог можно менять\n",
    "        frame_drawn = draw_detections(frame, det)\n",
    "\n",
    "        # запись кадра в ffmpeg writer\n",
    "        writer_proc.stdin.write(frame_drawn.tobytes())\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Обработан кадр {idx}\")\n",
    "finally:\n",
    "    if writer_proc.stdin is not None:\n",
    "        writer_proc.stdin.close()\n",
    "    writer_proc.wait()\n",
    "    print(\"Готово, выходное видео:\", output_path_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fb9991b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Размерности для удобства\n",
    "STATE_DIM = 7   # [x, y, a, h, vx, vy, va]\n",
    "MEAS_DIM  = 4   # [x, y, a, h]\n",
    "\n",
    "\n",
    "def xyxy_to_xyah(boxes_xyxy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    boxes_xyxy: (N, 4) [x1, y1, x2, y2]\n",
    "    → (N, 4) [x, y, a, h], где:\n",
    "      x, y — центр,\n",
    "      a    — aspect ratio = w / h,\n",
    "      h    — высота.\n",
    "    \"\"\"\n",
    "    boxes_xyxy = np.asarray(boxes_xyxy, dtype=np.float32)\n",
    "    if boxes_xyxy.size == 0:\n",
    "        return np.zeros((0, 4), dtype=np.float32)\n",
    "\n",
    "    x1 = boxes_xyxy[:, 0]\n",
    "    y1 = boxes_xyxy[:, 1]\n",
    "    x2 = boxes_xyxy[:, 2]\n",
    "    y2 = boxes_xyxy[:, 3]\n",
    "\n",
    "    w = x2 - x1\n",
    "    h = y2 - y1\n",
    "    x = x1 + 0.5 * w\n",
    "    y = y1 + 0.5 * h\n",
    "    a = w / np.maximum(h, 1e-6)\n",
    "\n",
    "    xyah = np.stack([x, y, a, h], axis=1).astype(np.float32)\n",
    "    return xyah\n",
    "\n",
    "\n",
    "def xyah_to_xyxy(boxes_xyah: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    boxes_xyah: (N, 4) [x, y, a, h]\n",
    "    → (N, 4) [x1, y1, x2, y2].\n",
    "    \"\"\"\n",
    "    boxes_xyah = np.asarray(boxes_xyah, dtype=np.float32)\n",
    "    if boxes_xyah.size == 0:\n",
    "        return np.zeros((0, 4), dtype=np.float32)\n",
    "\n",
    "    x = boxes_xyah[:, 0]\n",
    "    y = boxes_xyah[:, 1]\n",
    "    a = boxes_xyah[:, 2]\n",
    "    h = boxes_xyah[:, 3]\n",
    "\n",
    "    w = a * h\n",
    "    x1 = x - 0.5 * w\n",
    "    x2 = x + 0.5 * w\n",
    "    y1 = y - 0.5 * h\n",
    "    y2 = y + 0.5 * h\n",
    "\n",
    "    xyxy = np.stack([x1, y1, x2, y2], axis=1).astype(np.float32)\n",
    "    return xyxy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0f89af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_F(dt: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Матрица перехода состояния F для [x, y, a, h, vx, vy, va].\n",
    "    \"\"\"\n",
    "    F = np.eye(STATE_DIM, dtype=np.float32)\n",
    "    F[0, 4] = dt  # x += vx * dt\n",
    "    F[1, 5] = dt  # y += vy * dt\n",
    "    F[2, 6] = dt  # a += va * dt\n",
    "    # h считаем квазипостоянной (нет скорости)\n",
    "    return F\n",
    "\n",
    "\n",
    "def make_H() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Матрица измерения H: берём только [x, y, a, h] из состояния.\n",
    "    \"\"\"\n",
    "    H = np.zeros((MEAS_DIM, STATE_DIM), dtype=np.float32)\n",
    "    H[0, 0] = 1.0  # x\n",
    "    H[1, 1] = 1.0  # y\n",
    "    H[2, 2] = 1.0  # a\n",
    "    H[3, 3] = 1.0  # h\n",
    "    return H\n",
    "\n",
    "\n",
    "def make_R() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Матрица ковариации измерения R (шум детектора).\n",
    "    Простейшая диагональная настройка:\n",
    "\n",
    "      - x,y   — базовый шум (1.0)\n",
    "      - a,h   — считаем более шумными (10×)\n",
    "    \"\"\"\n",
    "    R = np.eye(MEAS_DIM, dtype=np.float32)\n",
    "    R[2, 2] *= 10.0\n",
    "    R[3, 3] *= 10.0\n",
    "    return R\n",
    "\n",
    "\n",
    "def make_Q() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Матрица процессного шума Q.\n",
    "    Близко к настройкам SORT/OC-SORT:\n",
    "\n",
    "      - положение/форма (первые 4) — единичный шум;\n",
    "      - скорости (последние 3)     — гораздо меньший шум (0.01),\n",
    "        чтобы они не разъезжались слишком быстро.\n",
    "\n",
    "    Для начала этого достаточно; позже можно будет отдельно\n",
    "    тюнить под конкретные сцены.\n",
    "    \"\"\"\n",
    "    Q = np.eye(STATE_DIM, dtype=np.float32)\n",
    "    Q[4:, 4:] *= 0.01  # скорости\n",
    "    return Q\n",
    "\n",
    "\n",
    "def make_initial_P() -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Начальная ковариация P для нового трека.\n",
    "\n",
    "    Аналогично SORT/OC-SORT:\n",
    "      - по [x, y, a, h] неопределённость умеренная;\n",
    "      - по скоростям огромная (1000×), т.к. мы их не наблюдаем напрямую,\n",
    "        только выводим из серии измерений.\n",
    "    Всё дополнительно масштабируем ×10 (как в SORT).\n",
    "    \"\"\"\n",
    "    P = np.eye(STATE_DIM, dtype=np.float32)\n",
    "    P[4:, 4:] *= 1000.0  # большие неопределённости по скоростям\n",
    "    P *= 10.0\n",
    "    return P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ccd8d183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KalmanFilterXYAH:\n",
    "    \"\"\"\n",
    "    Калман-фильтр в формате OC-SORT / DeepSORT для состояния:\n",
    "      x = [x, y, a, h, vx, vy, va]^T.\n",
    "\n",
    "    dt задаётся снаружи (обычно dt = 1 / FPS видео).\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dt: float):\n",
    "        self.dt = float(dt)\n",
    "\n",
    "        self.dim_x = STATE_DIM\n",
    "        self.dim_z = MEAS_DIM\n",
    "\n",
    "        # Состояние и ковариации\n",
    "        self.x = np.zeros(self.dim_x, dtype=np.float32)          # вектор состояния\n",
    "        self.P = make_initial_P()                                # ковариация\n",
    "\n",
    "        # Матричная структура\n",
    "        self.F = make_F(self.dt)                                 # переход\n",
    "        self.H = make_H()                                        # измерение\n",
    "        self.Q = make_Q()                                        # процессный шум\n",
    "        self.R = make_R()                                        # шум измерения\n",
    "\n",
    "        # Булевый флаг: инициализирован ли фильтр\n",
    "        self.initialized = False\n",
    "\n",
    "    # --- служебные методы ---\n",
    "\n",
    "    def _ensure_shape_meas(self, z_xyah: np.ndarray) -> np.ndarray:\n",
    "        z = np.asarray(z_xyah, dtype=np.float32).reshape(-1)\n",
    "        if z.shape[0] != self.dim_z:\n",
    "            raise ValueError(f\"Ожидается измерение размерности {self.dim_z}, \"\n",
    "                             f\"получено {z.shape[0]}\")\n",
    "        return z\n",
    "\n",
    "    # --- публичный интерфейс ---\n",
    "\n",
    "    def initiate(self, meas_xyah: np.ndarray):\n",
    "        \"\"\"\n",
    "        Инициализация фильтра по первой детекции [x, y, a, h].\n",
    "\n",
    "        Скорости (vx, vy, va) выставляются в 0, а неопределённость по ним\n",
    "        уже заложена в P (очень большая).\n",
    "        \"\"\"\n",
    "        z = self._ensure_shape_meas(meas_xyah)\n",
    "        self.x = np.zeros(self.dim_x, dtype=np.float32)\n",
    "        self.x[:4] = z\n",
    "        self.P = make_initial_P()\n",
    "        self.initialized = True\n",
    "\n",
    "    def predict(self) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Шаг предсказания:\n",
    "          x' = F x\n",
    "          P' = F P F^T + Q\n",
    "\n",
    "        Возвращает предсказанное измерение в формате [x, y, a, h].\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            raise RuntimeError(\"KalmanFilterXYAH: вызван predict() до initiate()\")\n",
    "\n",
    "        # x' = F x\n",
    "        self.x = self.F @ self.x\n",
    "        # P' = F P F^T + Q\n",
    "        self.P = self.F @ self.P @ self.F.T + self.Q\n",
    "\n",
    "        # возвращаем только измеряемую часть\n",
    "        return self.x[:4].copy()\n",
    "\n",
    "    def project(self) -> tuple[np.ndarray, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Проецирует текущее состояние в пространство измерений:\n",
    "          z_pred = H x\n",
    "          S      = H P H^T + R\n",
    "\n",
    "        Это будет нужно для Махаланобис-гейтинга на шаге 3.\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            raise RuntimeError(\"KalmanFilterXYAH: вызван project() до initiate()\")\n",
    "\n",
    "        z_pred = self.H @ self.x\n",
    "        S = self.H @ self.P @ self.H.T + self.R\n",
    "        return z_pred, S\n",
    "\n",
    "    def update(self, meas_xyah: np.ndarray):\n",
    "        \"\"\"\n",
    "        Шаг коррекции (обновления) по новому измерению z = [x, y, a, h].\n",
    "\n",
    "        Используется на шаге 4 после ассоциации детекций и треков.\n",
    "        \"\"\"\n",
    "        if not self.initialized:\n",
    "            raise RuntimeError(\"KalmanFilterXYAH: вызван update() до initiate()\")\n",
    "\n",
    "        z = self._ensure_shape_meas(meas_xyah)\n",
    "\n",
    "        # Инновация: y = z - H x'\n",
    "        z_pred, S = self.project()\n",
    "        y = z - z_pred\n",
    "\n",
    "        # Калмановский коэффициент: K = P H^T S^{-1}\n",
    "        K = self.P @ self.H.T @ np.linalg.inv(S)\n",
    "\n",
    "        # Обновление состояния: x = x' + K y\n",
    "        self.x = self.x + K @ y\n",
    "\n",
    "        # Обновление ковариации: P = (I - K H) P\n",
    "        I = np.eye(self.dim_x, dtype=np.float32)\n",
    "        self.P = (I - K @ self.H) @ self.P\n",
    "\n",
    "        # для удобства вернуть обновлённое \"измерение\"\n",
    "        return self.x[:4].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "418ded72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Пытаемся использовать SciPy, при отсутствии — простой жадный fallback\n",
    "try:\n",
    "    from scipy.optimize import linear_sum_assignment as _linear_sum_assignment\n",
    "    SCIPY_AVAILABLE = True\n",
    "except Exception:\n",
    "    SCIPY_AVAILABLE = False\n",
    "    _linear_sum_assignment = None\n",
    "\n",
    "\n",
    "def bbox_iou_matrix(boxes1_xyxy: np.ndarray, boxes2_xyxy: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Вычисляет IoU для всех пар боксов из boxes1 и boxes2.\n",
    "\n",
    "    boxes1_xyxy: (T, 4) [x1, y1, x2, y2]\n",
    "    boxes2_xyxy: (N, 4) [x1, y1, x2, y2]\n",
    "    → (T, N) матрица IoU.\n",
    "    \"\"\"\n",
    "    boxes1 = np.asarray(boxes1_xyxy, dtype=np.float32)\n",
    "    boxes2 = np.asarray(boxes2_xyxy, dtype=np.float32)\n",
    "    T = boxes1.shape[0]\n",
    "    N = boxes2.shape[0]\n",
    "    if T == 0 or N == 0:\n",
    "        return np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    x11 = boxes1[:, 0:1]\n",
    "    y11 = boxes1[:, 1:2]\n",
    "    x12 = boxes1[:, 2:3]\n",
    "    y12 = boxes1[:, 3:4]\n",
    "\n",
    "    x21 = boxes2[:, 0]\n",
    "    y21 = boxes2[:, 1]\n",
    "    x22 = boxes2[:, 2]\n",
    "    y22 = boxes2[:, 3]\n",
    "\n",
    "    inter_x1 = np.maximum(x11, x21)  # (T, N)\n",
    "    inter_y1 = np.maximum(y11, y21)\n",
    "    inter_x2 = np.minimum(x12, x22)\n",
    "    inter_y2 = np.minimum(y12, y22)\n",
    "\n",
    "    inter_w = np.clip(inter_x2 - inter_x1, a_min=0.0, a_max=None)\n",
    "    inter_h = np.clip(inter_y2 - inter_y1, a_min=0.0, a_max=None)\n",
    "    inter_area = inter_w * inter_h\n",
    "\n",
    "    area1 = (x12 - x11) * (y12 - y11)  # (T, 1)\n",
    "    area2 = (x22 - x21) * (y22 - y21)  # (N,)\n",
    "\n",
    "    union_area = area1 + area2 - inter_area  # broadcasting → (T, N)\n",
    "    iou = np.where(union_area > 0.0, inter_area / union_area, 0.0).astype(np.float32)\n",
    "    return iou\n",
    "\n",
    "\n",
    "def mahalanobis_gating_matrix(\n",
    "    tracks_xyah: np.ndarray,\n",
    "    tracks_S: np.ndarray,\n",
    "    dets_xyah: np.ndarray\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Махаланобисовы расстояния для всех пар (трек, детекция).\n",
    "\n",
    "    tracks_xyah: (T, 4)  — предсказанное измерение трека [x, y, a, h]\n",
    "    tracks_S:    (T, 4, 4) — ковариация измерения S = H P H^T + R\n",
    "    dets_xyah:   (N, 4)  — измерения детекций [x, y, a, h]\n",
    "\n",
    "    Возвращает матрицу d^2 (T, N), где d^2_ij — расстояние от трека i до детекции j.\n",
    "    \"\"\"\n",
    "    tracks_xyah = np.asarray(tracks_xyah, dtype=np.float32)\n",
    "    dets_xyah = np.asarray(dets_xyah, dtype=np.float32)\n",
    "    S = np.asarray(tracks_S, dtype=np.float32)\n",
    "\n",
    "    T = tracks_xyah.shape[0]\n",
    "    N = dets_xyah.shape[0]\n",
    "    if T == 0 or N == 0:\n",
    "        return np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    # Инвертируем ковариации треков\n",
    "    S_inv = np.linalg.inv(S)  # (T, 4, 4)\n",
    "\n",
    "    # diff[t, n, d] = z_det[n, d] - z_pred[t, d]\n",
    "    diff = dets_xyah[None, :, :] - tracks_xyah[:, None, :]  # (T, N, 4)\n",
    "\n",
    "    # temp[t, n, k] = Σ_d diff[t,n,d] * S_inv[t,d,k]\n",
    "    temp = np.einsum(\"tnd,tdk->tnk\", diff, S_inv)\n",
    "    # d2[t, n]      = Σ_k temp[t,n,k] * diff[t,n,k]\n",
    "    d2 = np.einsum(\"tnk,tnk->tn\", temp, diff)\n",
    "    return d2.astype(np.float32)\n",
    "\n",
    "\n",
    "def linear_assignment(cost_matrix: np.ndarray, cost_limit: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Обёртка над Венгерским алгоритмом.\n",
    "\n",
    "    cost_matrix: (T, N)  — матрица стоимостей (меньше = лучше)\n",
    "    cost_limit:  максимальная допустимая стоимость для матча.\n",
    "                 Если стоимость > cost_limit — пара считается нематчируемой.\n",
    "\n",
    "    Возвращает массив shape (K, 2), пары индексов (row_idx, col_idx).\n",
    "    \"\"\"\n",
    "    cost = np.asarray(cost_matrix, dtype=np.float32)\n",
    "    T, N = cost.shape\n",
    "    if T == 0 or N == 0:\n",
    "        return np.zeros((0, 2), dtype=np.int32)\n",
    "\n",
    "    if SCIPY_AVAILABLE:\n",
    "        row_ind, col_ind = _linear_sum_assignment(cost)\n",
    "        matches = []\n",
    "        for r, c in zip(row_ind, col_ind):\n",
    "            if cost[r, c] <= cost_limit:\n",
    "                matches.append((int(r), int(c)))\n",
    "        if not matches:\n",
    "            return np.zeros((0, 2), dtype=np.int32)\n",
    "        return np.asarray(matches, dtype=np.int32)\n",
    "\n",
    "    # Fallback: простой жадный выбор минимальных стоимостей\n",
    "    matches = []\n",
    "    used_rows = set()\n",
    "    used_cols = set()\n",
    "    while True:\n",
    "        best_val = float(\"inf\")\n",
    "        best_r = best_c = None\n",
    "        for r in range(T):\n",
    "            if r in used_rows:\n",
    "                continue\n",
    "            for c in range(N):\n",
    "                if c in used_cols:\n",
    "                    continue\n",
    "                v = cost[r, c]\n",
    "                if v < best_val:\n",
    "                    best_val = v\n",
    "                    best_r, best_c = r, c\n",
    "        if best_r is None or best_val > cost_limit:\n",
    "            break\n",
    "        matches.append((best_r, best_c))\n",
    "        used_rows.add(best_r)\n",
    "        used_cols.add(best_c)\n",
    "\n",
    "    if not matches:\n",
    "        return np.zeros((0, 2), dtype=np.int32)\n",
    "    return np.asarray(matches, dtype=np.int32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a6e485a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def byte_maha_associate(\n",
    "    tracks_xyah: np.ndarray,      # (T, 4)  предсказанное измерение трека [x, y, a, h]\n",
    "    tracks_S: np.ndarray,         # (T, 4, 4) ковариация S каждого трека\n",
    "    dets_xyxy: np.ndarray,        # (N, 4)  боксы детекций [x1,y1,x2,y2]\n",
    "    dets_xyah: np.ndarray,        # (N, 4)  измерения детекций [x, y, a, h]\n",
    "    dets_scores: np.ndarray,      # (N,)    score детекций\n",
    "    valid_size_mask: np.ndarray,  # (N,) bool — достаточная высота бокса\n",
    "    inside_roi_mask: np.ndarray,  # (N,) bool — бокс целиком внутри ROI\n",
    "    *,\n",
    "    thr_high: float = 0.5,\n",
    "    thr_low: float = 0.1,\n",
    "    iou_thresh_high: float = 0.1,\n",
    "    iou_thresh_low: float = 0.1,\n",
    "    gate_thresh: float = 9.4877,  # χ²_0.99(dof=4)\n",
    "    alpha: float = 0.5,\n",
    "    beta: float = 0.5,\n",
    "    appearance_cost_high: np.ndarray | None = None,  # (T, N) или None\n",
    "    track_classes: np.ndarray | None = None,         # (T,)  или None\n",
    "    det_classes: np.ndarray | None = None,           # (N,)  или None\n",
    "):\n",
    "    \"\"\"\n",
    "    Ассоциация по схеме:\n",
    "      A) High-conf: IoU + Махаланобис-гейтинг + Венгерский;\n",
    "      B) Остаток (tracks × high-conf dets): стоимость α·(1−IoU)+β·d_app;\n",
    "      C) ByteTrack: оставшиеся треки × low-conf dets по IoU (с гейтингом).\n",
    "\n",
    "    Важно:\n",
    "      - На вход подаются ВСЕ детекции текущего кадра;\n",
    "      - Каких именно детекций мы касаемся, определяют:\n",
    "           valid_size_mask, inside_roi_mask, thr_high, thr_low.\n",
    "\n",
    "    Возвращает словарь:\n",
    "      - matches_high: (K1, 2) пары (track_idx, det_idx) для high-conf (A+B);\n",
    "      - matches_low:  (K2, 2) пары (track_idx, det_idx) для low-conf (C);\n",
    "      - unmatched_tracks:        (T_u,) индексы треков без матчей;\n",
    "      - unmatched_dets_high:     (Nh_u,) индексы high-conf детекций без матчей;\n",
    "      - unmatched_dets_low:      (Nl_u,) индексы low-conf детекций без матчей.\n",
    "    \"\"\"\n",
    "    tracks_xyah = np.asarray(tracks_xyah, dtype=np.float32)\n",
    "    tracks_S = np.asarray(tracks_S, dtype=np.float32)\n",
    "    dets_xyxy = np.asarray(dets_xyxy, dtype=np.float32)\n",
    "    dets_xyah = np.asarray(dets_xyah, dtype=np.float32)\n",
    "    dets_scores = np.asarray(dets_scores, dtype=np.float32)\n",
    "    valid_size_mask = np.asarray(valid_size_mask, dtype=bool)\n",
    "    inside_roi_mask = np.asarray(inside_roi_mask, dtype=bool)\n",
    "\n",
    "    T = tracks_xyah.shape[0]\n",
    "    N = dets_xyxy.shape[0]\n",
    "    assert dets_xyah.shape[0] == N == dets_scores.shape[0]\n",
    "\n",
    "    # --- 0. Если треков нет, ничего не ассоциируем ---\n",
    "    if T == 0:\n",
    "        # Разбиваем детекции просто по порогам\n",
    "        det_valid = valid_size_mask & inside_roi_mask & (dets_scores >= thr_low)\n",
    "        high_mask = det_valid & (dets_scores >= thr_high)\n",
    "        low_mask = det_valid & (dets_scores < thr_high)\n",
    "\n",
    "        det_ids_high = np.where(high_mask)[0]\n",
    "        det_ids_low = np.where(low_mask)[0]\n",
    "\n",
    "        return {\n",
    "            \"matches_high\": np.zeros((0, 2), dtype=np.int32),\n",
    "            \"matches_low\": np.zeros((0, 2), dtype=np.int32),\n",
    "            \"unmatched_tracks\": np.zeros((0,), dtype=np.int32),\n",
    "            \"unmatched_dets_high\": det_ids_high,\n",
    "            \"unmatched_dets_low\": det_ids_low,\n",
    "        }\n",
    "\n",
    "    # --- 1. Разделяем детекции по ByteTrack-порогам и ROI/размеру ---\n",
    "\n",
    "    det_valid = valid_size_mask & inside_roi_mask & (dets_scores >= thr_low)\n",
    "    high_mask = det_valid & (dets_scores >= thr_high)\n",
    "    low_mask = det_valid & (dets_scores < thr_high)\n",
    "\n",
    "    det_ids_high = np.where(high_mask)[0]\n",
    "    det_ids_low = np.where(low_mask)[0]\n",
    "\n",
    "    # Для удобства\n",
    "    all_track_ids = np.arange(T, dtype=np.int32)\n",
    "\n",
    "    # Если нет ни одной валидной детекции\n",
    "    if det_ids_high.size == 0 and det_ids_low.size == 0:\n",
    "        return {\n",
    "            \"matches_high\": np.zeros((0, 2), dtype=np.int32),\n",
    "            \"matches_low\": np.zeros((0, 2), dtype=np.int32),\n",
    "            \"unmatched_tracks\": all_track_ids,\n",
    "            \"unmatched_dets_high\": det_ids_high,\n",
    "            \"unmatched_dets_low\": det_ids_low,\n",
    "        }\n",
    "\n",
    "    # Для всех треков заранее посчитаем bbox-форму (XYXY) из XYAH\n",
    "    def xyah_to_xyxy(boxes_xyah: np.ndarray) -> np.ndarray:\n",
    "        boxes_xyah = np.asarray(boxes_xyah, dtype=np.float32)\n",
    "        if boxes_xyah.size == 0:\n",
    "            return np.zeros((0, 4), dtype=np.float32)\n",
    "        x = boxes_xyah[:, 0]\n",
    "        y = boxes_xyah[:, 1]\n",
    "        a = boxes_xyah[:, 2]\n",
    "        h = boxes_xyah[:, 3]\n",
    "        w = a * h\n",
    "        x1 = x - 0.5 * w\n",
    "        x2 = x + 0.5 * w\n",
    "        y1 = y - 0.5 * h\n",
    "        y2 = y + 0.5 * h\n",
    "        return np.stack([x1, y1, x2, y2], axis=1).astype(np.float32)\n",
    "\n",
    "    tracks_xyxy = xyah_to_xyxy(tracks_xyah)\n",
    "\n",
    "    INF = 1e9\n",
    "\n",
    "    # ===================================================================\n",
    "    #  A) High-conf: IoU + Махаланобис-гейтинг\n",
    "    # ===================================================================\n",
    "\n",
    "    matches_high_list = []\n",
    "\n",
    "    matched_tracks_mask = np.zeros(T, dtype=bool)\n",
    "    matched_high_mask = np.zeros(det_ids_high.shape[0], dtype=bool)\n",
    "\n",
    "    if det_ids_high.size > 0:\n",
    "        dets_xyxy_high = dets_xyxy[det_ids_high]\n",
    "        dets_xyah_high = dets_xyah[det_ids_high]\n",
    "\n",
    "        # IoU и Махаланобис\n",
    "        iou_high = bbox_iou_matrix(tracks_xyxy, dets_xyxy_high)  # (T, Nh)\n",
    "        maha_high = mahalanobis_gating_matrix(tracks_xyah, tracks_S, dets_xyah_high)\n",
    "\n",
    "        valid_pair = (maha_high <= gate_thresh) & (iou_high >= iou_thresh_high)\n",
    "\n",
    "        cost_high = 1.0 - iou_high\n",
    "        cost_high[~valid_pair] = INF\n",
    "\n",
    "        # Классовые ограничения (если заданы)\n",
    "        if track_classes is not None and det_classes is not None:\n",
    "            track_classes = np.asarray(track_classes)\n",
    "            det_classes_high = np.asarray(det_classes)[det_ids_high]\n",
    "            class_mismatch = (track_classes[:, None] != det_classes_high[None, :])\n",
    "            cost_high[class_mismatch] = INF\n",
    "\n",
    "        # Ограничиваем стоимость реальных матчей диапазоном [0, 1]\n",
    "        matches_stage1_local = linear_assignment(cost_high, cost_limit=1.0)\n",
    "\n",
    "        for t_local, d_local in matches_stage1_local:\n",
    "            matched_tracks_mask[t_local] = True\n",
    "            matched_high_mask[d_local] = True\n",
    "            t_global = all_track_ids[t_local]\n",
    "            d_global = det_ids_high[d_local]\n",
    "            matches_high_list.append((t_global, d_global))\n",
    "\n",
    "    # --- треки и high-dets, оставшиеся после шага A ---\n",
    "    unmatched_tracks_A = all_track_ids[~matched_tracks_mask]\n",
    "    unmatched_high_ids_A = det_ids_high[~matched_high_mask]\n",
    "\n",
    "    # ===================================================================\n",
    "    #  B) Остаток (tracks × high-conf) с cost = α·(1−IoU)+β·d_app\n",
    "    # ===================================================================\n",
    "\n",
    "    if unmatched_tracks_A.size > 0 and unmatched_high_ids_A.size > 0:\n",
    "        t_ids_B = unmatched_tracks_A\n",
    "        d_ids_B = unmatched_high_ids_A\n",
    "\n",
    "        tracks_xyah_B = tracks_xyah[t_ids_B]\n",
    "        tracks_xyxy_B = xyah_to_xyxy(tracks_xyah_B)\n",
    "        tracks_S_B = tracks_S[t_ids_B]\n",
    "\n",
    "        dets_xyxy_B = dets_xyxy[d_ids_B]\n",
    "        dets_xyah_B = dets_xyah[d_ids_B]\n",
    "\n",
    "        iou_B = bbox_iou_matrix(tracks_xyxy_B, dets_xyxy_B)\n",
    "        maha_B = mahalanobis_gating_matrix(tracks_xyah_B, tracks_S_B, dets_xyah_B)\n",
    "\n",
    "        valid_pair_B = (maha_B <= gate_thresh) & (iou_B >= iou_thresh_high)\n",
    "\n",
    "        # appearance cost, если задана полная матрица (T, N)\n",
    "        if appearance_cost_high is not None:\n",
    "            appearance_cost_high = np.asarray(appearance_cost_high, dtype=np.float32)\n",
    "            d_app_B = appearance_cost_high[np.ix_(t_ids_B, d_ids_B)]\n",
    "        else:\n",
    "            d_app_B = np.zeros_like(iou_B, dtype=np.float32)\n",
    "\n",
    "        cost_B = alpha * (1.0 - iou_B) + beta * d_app_B\n",
    "        cost_B[~valid_pair_B] = INF\n",
    "\n",
    "        # Классовые ограничения (если заданы)\n",
    "        if track_classes is not None and det_classes is not None:\n",
    "            track_classes_B = np.asarray(track_classes)[t_ids_B]\n",
    "            det_classes_B = np.asarray(det_classes)[d_ids_B]\n",
    "            class_mismatch_B = (track_classes_B[:, None] != det_classes_B[None, :])\n",
    "            cost_B[class_mismatch_B] = INF\n",
    "\n",
    "        matches_stage2_local = linear_assignment(cost_B, cost_limit=INF - 1.0)\n",
    "\n",
    "        for idx in range(matches_stage2_local.shape[0]):\n",
    "            t_loc_B, d_loc_B = matches_stage2_local[idx]\n",
    "            t_global = t_ids_B[t_loc_B]\n",
    "            d_global = d_ids_B[d_loc_B]\n",
    "\n",
    "            # помечаем как заматченные\n",
    "            matched_tracks_mask[t_global] = True\n",
    "\n",
    "            # найдём позицию d_global в det_ids_high, чтобы отметить matched_high_mask\n",
    "            # (unmatched_high_ids_A — подмножество det_ids_high)\n",
    "            high_pos = np.where(det_ids_high == d_global)[0]\n",
    "            if high_pos.size > 0:\n",
    "                matched_high_mask[high_pos[0]] = True\n",
    "\n",
    "            matches_high_list.append((t_global, d_global))\n",
    "\n",
    "    # --- high-conf детекции, не использованные ни в A, ни в B ---\n",
    "    unmatched_high_ids_final = det_ids_high[~matched_high_mask]\n",
    "\n",
    "    # ===================================================================\n",
    "    #  C) ByteTrack: оставшиеся треки × low-conf детекции\n",
    "    # ===================================================================\n",
    "\n",
    "    matches_low_list = []\n",
    "    matched_low_mask = np.zeros(det_ids_low.shape[0], dtype=bool)\n",
    "\n",
    "    unmatched_tracks_after_AB = all_track_ids[~matched_tracks_mask]\n",
    "\n",
    "    if unmatched_tracks_after_AB.size > 0 and det_ids_low.size > 0:\n",
    "        t_ids_C = unmatched_tracks_after_AB\n",
    "        d_ids_C = det_ids_low\n",
    "\n",
    "        tracks_xyah_C = tracks_xyah[t_ids_C]\n",
    "        tracks_xyxy_C = xyah_to_xyxy(tracks_xyah_C)\n",
    "        tracks_S_C = tracks_S[t_ids_C]\n",
    "\n",
    "        dets_xyxy_C = dets_xyxy[d_ids_C]\n",
    "        dets_xyah_C = dets_xyah[d_ids_C]\n",
    "\n",
    "        iou_C = bbox_iou_matrix(tracks_xyxy_C, dets_xyxy_C)\n",
    "        maha_C = mahalanobis_gating_matrix(tracks_xyah_C, tracks_S_C, dets_xyah_C)\n",
    "\n",
    "        valid_pair_C = (maha_C <= gate_thresh) & (iou_C >= iou_thresh_low)\n",
    "\n",
    "        cost_C = 1.0 - iou_C\n",
    "        cost_C[~valid_pair_C] = INF\n",
    "\n",
    "        # Классовые ограничения (если заданы)\n",
    "        if track_classes is not None and det_classes is not None:\n",
    "            track_classes_C = np.asarray(track_classes)[t_ids_C]\n",
    "            det_classes_C = np.asarray(det_classes)[d_ids_C]\n",
    "            class_mismatch_C = (track_classes_C[:, None] != det_classes_C[None, :])\n",
    "            cost_C[class_mismatch_C] = INF\n",
    "\n",
    "        matches_stage3_local = linear_assignment(cost_C, cost_limit=1.0)\n",
    "\n",
    "        for idx in range(matches_stage3_local.shape[0]):\n",
    "            t_loc_C, d_loc_C = matches_stage3_local[idx]\n",
    "            t_global = t_ids_C[t_loc_C]\n",
    "            d_global = d_ids_C[d_loc_C]\n",
    "\n",
    "            matches_low_list.append((t_global, d_global))\n",
    "\n",
    "            # отметим конкретный low-conf детектор как использованный\n",
    "            low_pos = np.where(det_ids_low == d_global)[0]\n",
    "            if low_pos.size > 0:\n",
    "                matched_low_mask[low_pos[0]] = True\n",
    "\n",
    "    # ===================================================================\n",
    "    #  Итоговые множества unmatched\n",
    "    # ===================================================================\n",
    "\n",
    "    matches_high = (\n",
    "        np.asarray(matches_high_list, dtype=np.int32)\n",
    "        if matches_high_list else np.zeros((0, 2), dtype=np.int32)\n",
    "    )\n",
    "    matches_low = (\n",
    "        np.asarray(matches_low_list, dtype=np.int32)\n",
    "        if matches_low_list else np.zeros((0, 2), dtype=np.int32)\n",
    "    )\n",
    "\n",
    "    # треки, которые не получили ни high-, ни low-match\n",
    "    if matches_high.shape[0] > 0:\n",
    "        matched_tracks_high = np.unique(matches_high[:, 0])\n",
    "    else:\n",
    "        matched_tracks_high = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "    if matches_low.shape[0] > 0:\n",
    "        matched_tracks_low = np.unique(matches_low[:, 0])\n",
    "    else:\n",
    "        matched_tracks_low = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "    matched_tracks_all = np.union1d(matched_tracks_high, matched_tracks_low)\n",
    "    unmatched_tracks = np.setdiff1d(all_track_ids, matched_tracks_all, assume_unique=True)\n",
    "\n",
    "    # unmatched dets (high/low)\n",
    "    unmatched_dets_high = unmatched_high_ids_final\n",
    "    unmatched_dets_low = det_ids_low[~matched_low_mask]\n",
    "\n",
    "    return {\n",
    "        \"matches_high\": matches_high,\n",
    "        \"matches_low\": matches_low,\n",
    "        \"unmatched_tracks\": unmatched_tracks,\n",
    "        \"unmatched_dets_high\": unmatched_dets_high,\n",
    "        \"unmatched_dets_low\": unmatched_dets_low,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ec79a166",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Классы, для которых мы используем appearance (ReID)\n",
    "# COCO: 0 = person, 2 = car, 7 = truck и т.п.\n",
    "REID_ENABLED_CLASSES = {0}  # пока только person\n",
    "\n",
    "# Сколько последних эмбеддингов учитывать на треке\n",
    "REID_MAX_FEATURES = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d9461a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from enum import IntEnum\n",
    "import numpy as np\n",
    "\n",
    "class TrackState(IntEnum):\n",
    "    TENTATIVE = 0\n",
    "    CONFIRMED = 1\n",
    "    LOST = 2\n",
    "    REMOVED = 3\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Track:\n",
    "    track_id: int\n",
    "    kf: \"KalmanFilterXYAH\"\n",
    "    class_id: int\n",
    "    n_init: int\n",
    "    max_time_lost: int\n",
    "\n",
    "    state: TrackState = TrackState.TENTATIVE\n",
    "    hits: int = 1\n",
    "    age: int = 1\n",
    "    time_since_update: int = 0\n",
    "    score: float = 0.0\n",
    "\n",
    "    last_xyah: np.ndarray = field(default_factory=lambda: np.zeros(4, dtype=np.float32))\n",
    "    last_S:   np.ndarray = field(default_factory=lambda: np.eye(4, dtype=np.float32))\n",
    "\n",
    "    trajectory_xyxy: list = field(default_factory=list)\n",
    "    features: list = field(default_factory=list)  # список np.ndarray (appearance-фичи)\n",
    "\n",
    "    # --- состояния ---\n",
    "\n",
    "    def is_tentative(self) -> bool:\n",
    "        return self.state == TrackState.TENTATIVE\n",
    "\n",
    "    def is_confirmed(self) -> bool:\n",
    "        return self.state == TrackState.CONFIRMED\n",
    "\n",
    "    def is_lost(self) -> bool:\n",
    "        return self.state == TrackState.LOST\n",
    "\n",
    "    def is_removed(self) -> bool:\n",
    "        return self.state == TrackState.REMOVED\n",
    "\n",
    "    # --- инициализация ---\n",
    "\n",
    "    def initiate_from_detection(self, meas_xyah: np.ndarray, score: float, feature: np.ndarray | None = None):\n",
    "        self.kf.initiate(meas_xyah)\n",
    "        z_pred, S = self.kf.project()\n",
    "        self.last_xyah = z_pred\n",
    "        self.last_S = S\n",
    "        self.score = float(score)\n",
    "        self.age = 1\n",
    "        self.hits = 1\n",
    "        self.time_since_update = 0\n",
    "\n",
    "        xyxy = xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "        self.trajectory_xyxy.append(xyxy)\n",
    "\n",
    "        if feature is not None:\n",
    "            self.features.append(feature)\n",
    "\n",
    "    # --- предсказание ---\n",
    "\n",
    "    def predict(self):\n",
    "        if not self.kf.initialized:\n",
    "            return\n",
    "\n",
    "        self.kf.predict()\n",
    "        z_pred, S = self.kf.project()\n",
    "        self.last_xyah = z_pred\n",
    "        self.last_S = S\n",
    "\n",
    "        self.age += 1\n",
    "        self.time_since_update += 1\n",
    "\n",
    "        xyxy = xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "        self.trajectory_xyxy.append(xyxy)\n",
    "\n",
    "    # --- обновление по детекции ---\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        meas_xyah: np.ndarray,\n",
    "        score: float,\n",
    "        feature: np.ndarray | None = None,\n",
    "        use_kalman: bool = True,\n",
    "    ):\n",
    "        self.time_since_update = 0\n",
    "        self.hits += 1\n",
    "        self.score = float(score)\n",
    "\n",
    "        if use_kalman:\n",
    "            self.kf.update(meas_xyah)\n",
    "\n",
    "        z_pred, S = self.kf.project()\n",
    "        self.last_xyah = z_pred\n",
    "        self.last_S = S\n",
    "\n",
    "        xyxy = xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "        if self.trajectory_xyxy:\n",
    "            self.trajectory_xyxy[-1] = xyxy\n",
    "        else:\n",
    "            self.trajectory_xyxy.append(xyxy)\n",
    "\n",
    "        if feature is not None:\n",
    "            self.features.append(feature)\n",
    "\n",
    "        if self.state == TrackState.TENTATIVE and self.hits >= self.n_init:\n",
    "            self.state = TrackState.CONFIRMED\n",
    "        elif self.state == TrackState.LOST:\n",
    "            self.state = TrackState.CONFIRMED\n",
    "\n",
    "    # --- \"пропуск\" кадра ---\n",
    "\n",
    "    def mark_missed(self):\n",
    "        if self.state == TrackState.TENTATIVE:\n",
    "            self.state = TrackState.REMOVED\n",
    "        elif self.state in (TrackState.CONFIRMED, TrackState.LOST):\n",
    "            if self.time_since_update > self.max_time_lost:\n",
    "                self.state = TrackState.REMOVED\n",
    "            else:\n",
    "                self.state = TrackState.LOST\n",
    "\n",
    "    # --- геттеры ---\n",
    "\n",
    "    def current_xyxy(self) -> np.ndarray:\n",
    "        return xyah_to_xyxy(self.last_xyah[None, :])[0]\n",
    "\n",
    "    # --- ID-банк (усреднение последних K фич) ---\n",
    "\n",
    "    def get_feature_centroid(self, max_k: int = REID_MAX_FEATURES) -> np.ndarray | None:\n",
    "        \"\"\"\n",
    "        Возвращает L2-нормированный центроид последних max_k appearance-фич\n",
    "        или None, если фич ещё нет.\n",
    "        \"\"\"\n",
    "        if not self.features:\n",
    "            return None\n",
    "\n",
    "        feats = self.features[-int(max_k):]\n",
    "        arr = np.stack(feats, axis=0).astype(np.float32)\n",
    "\n",
    "        # на всякий случай ещё раз L2-нормируем каждую фичу\n",
    "        norms = np.linalg.norm(arr, axis=1, keepdims=True) + 1e-12\n",
    "        arr = arr / norms\n",
    "\n",
    "        centroid = arr.mean(axis=0)\n",
    "        c_norm = float(np.linalg.norm(centroid))\n",
    "        if c_norm > 0.0:\n",
    "            centroid /= c_norm\n",
    "        return centroid\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f18ab7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_appearance_cost_matrix(\n",
    "    tracks: list[Track],\n",
    "    det_classes: np.ndarray,\n",
    "    det_features: np.ndarray,\n",
    "    enabled_classes: set[int] = REID_ENABLED_CLASSES,\n",
    "    max_features: int = REID_MAX_FEATURES,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Строит матрицу d_app (T, N) по косинусной дистанции:\n",
    "      d_app = 1 - cos_sim(track_centroid, det_feature).\n",
    "\n",
    "    Для пар (трек, детекция), где:\n",
    "      - класс не в enabled_classes,\n",
    "      - или классы не совпадают,\n",
    "      - или у трека нет фич\n",
    "    → d_app = 0 (appearance там не используется, решает motion).\n",
    "    \"\"\"\n",
    "    if not tracks:\n",
    "        return np.zeros((0, det_features.shape[0]), dtype=np.float32)\n",
    "\n",
    "    det_classes = np.asarray(det_classes, dtype=np.int32)\n",
    "    det_features = np.asarray(det_features, dtype=np.float32)\n",
    "\n",
    "    T = len(tracks)\n",
    "    N = det_features.shape[0]\n",
    "\n",
    "    if N == 0:\n",
    "        return np.zeros((T, 0), dtype=np.float32)\n",
    "\n",
    "    # предполагаем, что det_features уже L2-нормированы (как в ColorHistAppearance)\n",
    "    cost_app = np.zeros((T, N), dtype=np.float32)\n",
    "\n",
    "    for ti, tr in enumerate(tracks):\n",
    "        if tr.class_id not in enabled_classes:\n",
    "            continue\n",
    "\n",
    "        centroid = tr.get_feature_centroid(max_k=max_features)\n",
    "        if centroid is None:\n",
    "            continue\n",
    "\n",
    "        # только детекции того же класса\n",
    "        same_cls = (det_classes == tr.class_id)\n",
    "        idxs = np.where(same_cls)[0]\n",
    "        if idxs.size == 0:\n",
    "            continue\n",
    "\n",
    "        # cos_sim = <track_centroid, det_feature>\n",
    "        sims = det_features[idxs] @ centroid  # (K,)\n",
    "        sims = np.clip(sims, -1.0, 1.0)\n",
    "        d_app = 1.0 - sims  # 0 — \"очень похожи\", 2 — совсем разные\n",
    "\n",
    "        cost_app[ti, idxs] = d_app.astype(np.float32)\n",
    "\n",
    "    return cost_app\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1bb91271",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tracker:\n",
    "    \"\"\"\n",
    "    Трекер DeepSORT/OC-SORT-стиля с appearance:\n",
    "\n",
    "      - Калман [x,y,a,h,vx,vy,va]\n",
    "      - ByteTrack + Махаланобис + Венгерский\n",
    "      - Жизненный цикл треков\n",
    "      - ID-банк appearance (усреднение последних фич)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        fps: float,\n",
    "        n_init: int = 3,\n",
    "        max_time_lost: int = 30,\n",
    "        thr_high: float = 0.5,\n",
    "        thr_low: float = 0.1,\n",
    "        iou_thresh_high: float = 0.1,\n",
    "        iou_thresh_low: float = 0.1,\n",
    "        gate_thresh: float = 9.4877,\n",
    "        alpha: float = 0.5,\n",
    "        beta: float = 0.5,\n",
    "        track_conf_thr: float = 0.85,\n",
    "    ):\n",
    "        self.dt = 1.0 / float(fps)\n",
    "        self.n_init = int(n_init)\n",
    "        self.max_time_lost = int(max_time_lost)\n",
    "\n",
    "        self.thr_high = float(thr_high)\n",
    "        self.thr_low = float(thr_low)\n",
    "        self.iou_thresh_high = float(iou_thresh_high)\n",
    "        self.iou_thresh_low = float(iou_thresh_low)\n",
    "        self.gate_thresh = float(gate_thresh)\n",
    "        self.alpha = float(alpha)\n",
    "        self.beta = float(beta)\n",
    "        self.track_conf_thr = float(track_conf_thr)\n",
    "\n",
    "        self.tracks: list[Track] = []\n",
    "        self._next_id: int = 1\n",
    "\n",
    "    # --- создание нового трека ---\n",
    "\n",
    "    def _spawn_track(\n",
    "        self,\n",
    "        meas_xyah: np.ndarray,\n",
    "        score: float,\n",
    "        class_id: int,\n",
    "        feature: np.ndarray | None = None,\n",
    "    ):\n",
    "        kf = KalmanFilterXYAH(dt=self.dt)\n",
    "        tr = Track(\n",
    "            track_id=self._next_id,\n",
    "            kf=kf,\n",
    "            class_id=int(class_id),\n",
    "            n_init=self.n_init,\n",
    "            max_time_lost=self.max_time_lost,\n",
    "        )\n",
    "        tr.initiate_from_detection(meas_xyah, score, feature=feature)\n",
    "        self.tracks.append(tr)\n",
    "        self._next_id += 1\n",
    "\n",
    "    # --- основной шаг ---\n",
    "\n",
    "    def update(\n",
    "        self,\n",
    "        det: dict,\n",
    "        det_features: np.ndarray | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Обновление трекера по детекциям одного кадра.\n",
    "\n",
    "        det — словарь от run_yolo10_on_frame(...):\n",
    "            \"xyxy\", \"scores\", \"cls\",\n",
    "            \"valid_size_mask\", \"inside_roi_mask\", ...\n",
    "\n",
    "        det_features — (N, D) appearance-фичи детекций (L2-нормированные).\n",
    "                       Если None, ассоциация работает только по motion/IoU.\n",
    "        \"\"\"\n",
    "        # 1. Удаляем REMOVED-треки\n",
    "        self.tracks = [t for t in self.tracks if not t.is_removed()]\n",
    "\n",
    "        # 2. Предсказание\n",
    "        for t in self.tracks:\n",
    "            t.predict()\n",
    "\n",
    "        T = len(self.tracks)\n",
    "\n",
    "        if T > 0:\n",
    "            tracks_xyah = np.stack([t.last_xyah for t in self.tracks], axis=0)\n",
    "            tracks_S = np.stack([t.last_S for t in self.tracks], axis=0)\n",
    "            track_classes = np.array([t.class_id for t in self.tracks], dtype=np.int32)\n",
    "        else:\n",
    "            tracks_xyah = np.zeros((0, 4), dtype=np.float32)\n",
    "            tracks_S = np.zeros((0, 4, 4), dtype=np.float32)\n",
    "            track_classes = np.zeros((0,), dtype=np.int32)\n",
    "\n",
    "        # 3. Детекции кадра\n",
    "        dets_xyxy = np.asarray(det[\"xyxy\"], dtype=np.float32)\n",
    "        scores = np.asarray(det[\"scores\"], dtype=np.float32)\n",
    "        det_classes = np.asarray(det[\"cls\"], dtype=np.int32)\n",
    "        valid_size_mask = np.asarray(det[\"valid_size_mask\"], dtype=bool)\n",
    "        inside_roi_mask = np.asarray(det[\"inside_roi_mask\"], dtype=bool)\n",
    "\n",
    "        N = dets_xyxy.shape[0]\n",
    "\n",
    "        if N == 0:\n",
    "            for t in self.tracks:\n",
    "                t.mark_missed()\n",
    "            self.tracks = [t for t in self.tracks if not t.is_removed()]\n",
    "            return self.tracks\n",
    "\n",
    "        dets_xyah = xyxy_to_xyah(dets_xyxy)\n",
    "\n",
    "        # 4. appearance-cost (ReID) для high-conf части\n",
    "        appearance_cost_high = None\n",
    "        if det_features is not None and T > 0:\n",
    "            appearance_cost_high = compute_appearance_cost_matrix(\n",
    "                tracks=self.tracks,\n",
    "                det_classes=det_classes,\n",
    "                det_features=det_features,\n",
    "                enabled_classes=REID_ENABLED_CLASSES,\n",
    "                max_features=REID_MAX_FEATURES,\n",
    "            )\n",
    "\n",
    "        # 5. Ассоциация\n",
    "        assoc = byte_maha_associate(\n",
    "            tracks_xyah=tracks_xyah,\n",
    "            tracks_S=tracks_S,\n",
    "            dets_xyxy=dets_xyxy,\n",
    "            dets_xyah=dets_xyah,\n",
    "            dets_scores=scores,\n",
    "            valid_size_mask=valid_size_mask,\n",
    "            inside_roi_mask=inside_roi_mask,\n",
    "            thr_high=self.thr_high,\n",
    "            thr_low=self.thr_low,\n",
    "            iou_thresh_high=self.iou_thresh_high,\n",
    "            iou_thresh_low=self.iou_thresh_low,\n",
    "            gate_thresh=self.gate_thresh,\n",
    "            alpha=self.alpha,\n",
    "            beta=self.beta,\n",
    "            appearance_cost_high=appearance_cost_high,\n",
    "            track_classes=track_classes,\n",
    "            det_classes=det_classes,\n",
    "        )\n",
    "\n",
    "        matches_high = assoc[\"matches_high\"]\n",
    "        matches_low  = assoc[\"matches_low\"]\n",
    "        unmatched_tracks_idx = assoc[\"unmatched_tracks\"]\n",
    "        unmatched_dets_high = assoc[\"unmatched_dets_high\"]\n",
    "        unmatched_dets_low = assoc[\"unmatched_dets_low\"]\n",
    "\n",
    "        matched_tracks = np.zeros(T, dtype=bool)\n",
    "\n",
    "        # 6. High-conf матчи\n",
    "        for t_idx, d_idx in matches_high:\n",
    "            matched_tracks[t_idx] = True\n",
    "            meas_xyah = dets_xyah[d_idx]\n",
    "            sc = scores[d_idx]\n",
    "            feat = None\n",
    "            if det_features is not None:\n",
    "                feat = det_features[d_idx]\n",
    "\n",
    "            use_kalman = (sc >= self.track_conf_thr)\n",
    "\n",
    "            self.tracks[t_idx].update(\n",
    "                meas_xyah,\n",
    "                score=sc,\n",
    "                feature=feat,\n",
    "                use_kalman=use_kalman,\n",
    "            )\n",
    "\n",
    "        # 7. Low-conf ByteTrack-цепочка\n",
    "        for t_idx, d_idx in matches_low:\n",
    "            matched_tracks[t_idx] = True\n",
    "            meas_xyah = dets_xyah[d_idx]\n",
    "            sc = scores[d_idx]\n",
    "            feat = None\n",
    "            if det_features is not None:\n",
    "                feat = det_features[d_idx]\n",
    "\n",
    "            use_kalman = (sc >= self.track_conf_thr)\n",
    "\n",
    "            self.tracks[t_idx].update(\n",
    "                meas_xyah,\n",
    "                score=sc,\n",
    "                feature=feat,\n",
    "                use_kalman=use_kalman,\n",
    "            )\n",
    "\n",
    "        # 8. Треки без матча\n",
    "        for t_idx, tr in enumerate(self.tracks):\n",
    "            if not matched_tracks[t_idx]:\n",
    "                tr.mark_missed()\n",
    "\n",
    "        # 9. Новые треки из unmatched high-conf детекций\n",
    "        for d_idx in unmatched_dets_high:\n",
    "            meas_xyah = dets_xyah[d_idx]\n",
    "            sc = scores[d_idx]\n",
    "            class_id = det_classes[d_idx]\n",
    "            feat = None\n",
    "            if det_features is not None:\n",
    "                feat = det_features[d_idx]\n",
    "            self._spawn_track(meas_xyah, sc, int(class_id), feature=feat)\n",
    "\n",
    "        # 10. Чистка REMOVED\n",
    "        self.tracks = [t for t in self.tracks if not t.is_removed()]\n",
    "        return self.tracks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9d717390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Пример: инициализация трекера (после определения fps)\n",
    "orig_w, orig_h, fps = get_video_info(video_path)\n",
    "tracker = Tracker(\n",
    "    fps=fps,\n",
    "    n_init=3,\n",
    "    max_time_lost=30,\n",
    "    thr_high=0.5,\n",
    "    thr_low=0.1,\n",
    "    track_conf_thr=TRACK_CONF_THR,  # тот же, что в детекторе\n",
    ")\n",
    "\n",
    "# В основном цикле по кадрам:\n",
    "# for idx, frame in enumerate(gen):\n",
    "#     det = run_yolo10_on_frame(frame, conf_thr=0.25)\n",
    "#     tracks = tracker.update(det)\n",
    "#\n",
    "#     # дальше можно рисовать треки вместо \"сырых\" боксов:\n",
    "#     # например, только CONFIRMED:\n",
    "#     # for tr in tracks:\n",
    "#     #     if tr.is_confirmed():\n",
    "#     #         box = tr.current_xyxy()\n",
    "#     #         track_id = tr.track_id\n",
    "#     #         class_id = tr.class_id\n",
    "#     #         ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cc1ffeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def draw_tracks_on_frame(\n",
    "    frame_bgr: np.ndarray,\n",
    "    tracks: list,\n",
    "    draw_tentative: bool = True,\n",
    "    draw_lost: bool = False,\n",
    "    traj_len: int = 30,\n",
    "):\n",
    "    \"\"\"\n",
    "    Рисует треки поверх кадра.\n",
    "\n",
    "    Цвета по состоянию трека:\n",
    "      - CONFIRMED — ярко-зелёный\n",
    "      - TENTATIVE — жёлтый\n",
    "      - LOST      — фиолетовый (опционально, draw_lost=True)\n",
    "    Толщина линий = 1, fontScale = 0.42 (как ты просил).\n",
    "\n",
    "    Дополнительно:\n",
    "      - рисуем короткую траекторию (последние traj_len центров бокса).\n",
    "    \"\"\"\n",
    "    img = frame_bgr.copy()\n",
    "\n",
    "    for tr in tracks:\n",
    "        if tr.is_removed():\n",
    "            continue\n",
    "\n",
    "        if tr.is_confirmed():\n",
    "            color = (0, 255, 0)      # зелёный\n",
    "        elif tr.is_tentative():\n",
    "            if not draw_tentative:\n",
    "                continue\n",
    "            color = (0, 255, 255)    # жёлтый\n",
    "        elif tr.is_lost():\n",
    "            if not draw_lost:\n",
    "                continue\n",
    "            color = (255, 0, 255)    # фиолетовый\n",
    "        else:\n",
    "            # на всякий случай\n",
    "            color = (255, 255, 255)\n",
    "\n",
    "        # Текущий бокс\n",
    "        box_xyxy = tr.current_xyxy()\n",
    "        x1, y1, x2, y2 = box_xyxy\n",
    "        p1 = (int(x1), int(y1))\n",
    "        p2 = (int(x2), int(y2))\n",
    "\n",
    "        # Рисуем рамку трека\n",
    "        cv2.rectangle(img, p1, p2, color, 1)\n",
    "\n",
    "        # Подпись: ID и класс\n",
    "        label = f\"ID {tr.track_id} | c{tr.class_id}\"\n",
    "        cv2.putText(\n",
    "            img,\n",
    "            label,\n",
    "            (int(x1), int(y1) - 7),\n",
    "            cv2.FONT_HERSHEY_SIMPLEX,\n",
    "            0.42,\n",
    "            color,\n",
    "            1,\n",
    "            cv2.LINE_AA,\n",
    "        )\n",
    "\n",
    "        # Траектория (центры боксов за последние traj_len шагов)\n",
    "        if tr.trajectory_xyxy:\n",
    "            traj = tr.trajectory_xyxy[-traj_len:]\n",
    "            pts = []\n",
    "            for bx in traj:\n",
    "                cx = 0.5 * (bx[0] + bx[2])\n",
    "                cy = 0.5 * (bx[1] + bx[3])\n",
    "                pts.append((int(cx), int(cy)))\n",
    "\n",
    "            if len(pts) >= 2:\n",
    "                pts_arr = np.array(pts, dtype=np.int32).reshape((-1, 1, 2))\n",
    "                cv2.polylines(img, [pts_arr], isClosed=False, color=color, thickness=1)\n",
    "\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "af086270",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Путь к входному видео и выходному видео с треками\n",
    "# video_path = r\"vid.mp4\"\n",
    "# output_path_1_4 = r\"output_tracks(1_4).mp4\"\n",
    "\n",
    "# # 1. Узнаём fps и размер\n",
    "# orig_w, orig_h, fps = get_video_info(video_path)\n",
    "# print(f\"Видео: {orig_w}x{orig_h}, fps={fps:.3f}\")\n",
    "\n",
    "# # 2. Инициализируем трекер\n",
    "# tracker = Tracker(\n",
    "#     fps=fps,\n",
    "#     n_init=3,\n",
    "#     max_time_lost=30,\n",
    "#     thr_high=0.5,\n",
    "#     thr_low=0.1,\n",
    "#     iou_thresh_high=0.3,   # было 0.1\n",
    "#     iou_thresh_low=0.1,\n",
    "#     gate_thresh=5.99,      # вместо 9.48\n",
    "#     alpha=0.5,\n",
    "#     beta=0.5,\n",
    "#     track_conf_thr=TRACK_CONF_THR,\n",
    "# )\n",
    "\n",
    "\n",
    "# # 3. ffmpeg-генератор и writer\n",
    "# gen = ffmpeg_frame_generator(video_path, resize_to=None)\n",
    "# writer_proc = create_ffmpeg_writer(output_path_1_4, orig_w, orig_h, fps)\n",
    "\n",
    "# try:\n",
    "#     for idx, frame in enumerate(gen):\n",
    "#         # --- Шаг 1: детекция ---\n",
    "#         det = run_yolo10_on_frame(frame, conf_thr=0.25)\n",
    "\n",
    "#         # --- Шаги 2–4: Калман + ассоциация + жизненный цикл ---\n",
    "#         tracks = tracker.update(det)\n",
    "\n",
    "#         # --- Визуализация ---\n",
    "#         # Сначала нарисуем ROI и детекции (цвета по твоей логике)\n",
    "#         frame_det = draw_detections(frame, det)\n",
    "#         # Сверху нарисуем треки (ID, траектории)\n",
    "#         frame_out = draw_tracks_on_frame(frame_det, tracks)\n",
    "\n",
    "#         # Записываем кадр в ffmpeg\n",
    "#         writer_proc.stdin.write(frame_out.tobytes())\n",
    "\n",
    "#         if idx % 50 == 0:\n",
    "#             print(f\"Обработан кадр {idx}\")\n",
    "# finally:\n",
    "#     if writer_proc.stdin is not None:\n",
    "#         writer_proc.stdin.close()\n",
    "#     ret = writer_proc.wait()\n",
    "#     print(\"ffmpeg завершился с кодом\", ret)\n",
    "#     print(\"Готово, выходное видео:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b07e57f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e9cd6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "class ColorHistAppearance:\n",
    "    \"\"\"\n",
    "    Очень простой appearance-признак:\n",
    "      - обрезаем bbox\n",
    "      - переводим в HSV\n",
    "      - считаем 2D гистограмму по (H, S)\n",
    "      - нормируем (L1 + L2)\n",
    "    На выходе: L2-нормированный вектор длины h_bins * s_bins.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, h_bins: int = 16, s_bins: int = 16):\n",
    "        self.h_bins = int(h_bins)\n",
    "        self.s_bins = int(s_bins)\n",
    "        self.dim = self.h_bins * self.s_bins\n",
    "\n",
    "    def extract_for_detections(self, frame_bgr: np.ndarray, det: dict) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        det[\"xyxy\"]: (N,4) — боксы.\n",
    "        Возвращает (N, D) массив эмбеддингов (D = self.dim), L2-нормированных.\n",
    "        Для некорректных/слишком маленьких боксов — нулевой вектор.\n",
    "        \"\"\"\n",
    "        boxes = np.asarray(det[\"xyxy\"], dtype=np.float32)\n",
    "        N = boxes.shape[0]\n",
    "        if N == 0:\n",
    "            return np.zeros((0, self.dim), dtype=np.float32)\n",
    "\n",
    "        H, W, _ = frame_bgr.shape\n",
    "        feats = []\n",
    "\n",
    "        for (x1, y1, x2, y2) in boxes:\n",
    "            x1_i = int(round(x1))\n",
    "            y1_i = int(round(y1))\n",
    "            x2_i = int(round(x2))\n",
    "            y2_i = int(round(y2))\n",
    "\n",
    "            x1_i = max(0, min(W - 1, x1_i))\n",
    "            x2_i = max(0, min(W, x2_i))\n",
    "            y1_i = max(0, min(H - 1, y1_i))\n",
    "            y2_i = max(0, min(H, y2_i))\n",
    "\n",
    "            # совсем маленькие или вырожденные боксы\n",
    "            if x2_i <= x1_i + 1 or y2_i <= y1_i + 1:\n",
    "                feats.append(np.zeros(self.dim, dtype=np.float32))\n",
    "                continue\n",
    "\n",
    "            crop = frame_bgr[y1_i:y2_i, x1_i:x2_i]\n",
    "            hsv = cv2.cvtColor(crop, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "            hist = cv2.calcHist(\n",
    "                [hsv],\n",
    "                channels=[0, 1],\n",
    "                mask=None,\n",
    "                histSize=[self.h_bins, self.s_bins],\n",
    "                ranges=[0, 180, 0, 256],\n",
    "            )\n",
    "            hist = hist.flatten().astype(np.float32)\n",
    "\n",
    "            # L1-нормировка\n",
    "            s = float(hist.sum())\n",
    "            if s > 0.0:\n",
    "                hist /= s\n",
    "\n",
    "            # L2-нормировка\n",
    "            norm = float(np.linalg.norm(hist))\n",
    "            if norm > 0.0:\n",
    "                hist /= norm\n",
    "\n",
    "            feats.append(hist)\n",
    "\n",
    "        feats = np.stack(feats, axis=0)\n",
    "        return feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1c6a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "479efcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Видео: 1280x720, fps=25.000\n",
      "Видео: 1280x720, fps=25.000\n",
      "Обработан кадр 0\n",
      "Обработан кадр 50\n",
      "Обработан кадр 100\n",
      "Обработан кадр 150\n",
      "Обработан кадр 200\n",
      "Обработан кадр 250\n",
      "Обработан кадр 300\n",
      "Обработан кадр 350\n",
      "Обработан кадр 400\n",
      "Обработан кадр 450\n",
      "Обработан кадр 500\n",
      "Обработан кадр 550\n",
      "Обработан кадр 600\n",
      "Обработан кадр 650\n",
      "Обработан кадр 700\n",
      "Обработан кадр 750\n",
      "Обработан кадр 800\n",
      "Обработан кадр 850\n",
      "Обработан кадр 900\n",
      "Обработан кадр 950\n",
      "Обработан кадр 1000\n",
      "Обработан кадр 1050\n",
      "Обработан кадр 1100\n",
      "Обработан кадр 1150\n",
      "ffmpeg завершился с кодом 0\n",
      "Готово, выходное видео: output_1_5.mp4\n"
     ]
    }
   ],
   "source": [
    "# Инициализация\n",
    "output_path_1_5 = r\"output_1_5.mp4\"\n",
    "orig_w, orig_h, fps = get_video_info(video_path)\n",
    "print(f\"Видео: {orig_w}x{orig_h}, fps={fps:.3f}\")\n",
    "\n",
    "tracker = Tracker(\n",
    "    fps=fps,\n",
    "    n_init=3,\n",
    "    max_time_lost=30,\n",
    "    thr_high=0.5,\n",
    "    thr_low=0.1,\n",
    "    iou_thresh_high=0.3,   # чуть жёстче, чем 0.1\n",
    "    iou_thresh_low=0.1,\n",
    "    gate_thresh=5.99,      # можно немного ужать гейтинг\n",
    "    alpha=0.5,\n",
    "    beta=0.5,\n",
    "    track_conf_thr=TRACK_CONF_THR,\n",
    ")\n",
    "\n",
    "appearance_model = ColorHistAppearance(h_bins=16, s_bins=16)\n",
    "\n",
    "gen = ffmpeg_frame_generator(video_path, resize_to=None)\n",
    "writer_proc = create_ffmpeg_writer(output_path_1_5, orig_w, orig_h, fps)\n",
    "\n",
    "try:\n",
    "    for idx, frame in enumerate(gen):\n",
    "        # 1) детектор\n",
    "        det = run_yolo10_on_frame(frame, conf_thr=0.25)\n",
    "\n",
    "        # 2) appearance-фичи для всех детекций этого кадра\n",
    "        det_features = appearance_model.extract_for_detections(frame, det)\n",
    "\n",
    "        # 3) трекер с учётом appearance\n",
    "        tracks = tracker.update(det, det_features=det_features)\n",
    "\n",
    "        # 4) визуализация\n",
    "        frame_det = draw_detections(frame, det)\n",
    "        frame_out = draw_tracks_on_frame(frame_det, tracks)\n",
    "\n",
    "        writer_proc.stdin.write(frame_out.tobytes())\n",
    "\n",
    "        if idx % 50 == 0:\n",
    "            print(f\"Обработан кадр {idx}\")\n",
    "finally:\n",
    "    if writer_proc.stdin is not None:\n",
    "        writer_proc.stdin.close()\n",
    "    ret = writer_proc.wait()\n",
    "    print(\"ffmpeg завершился с кодом\", ret)\n",
    "    print(\"Готово, выходное видео:\", output_path_1_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fa4760",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1235c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164fa62d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
